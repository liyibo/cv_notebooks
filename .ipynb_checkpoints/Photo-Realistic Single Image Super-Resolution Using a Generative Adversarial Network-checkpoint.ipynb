{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管使用更快和更深的卷积神经网络在单幅图像超分辨率的准确性和速度方面取得了突破，但是一个中心问题仍然很大程度上没有解决：在大尺度缩放的图像上进行超分辨率重建时，如何恢复更精细的纹理特征？基于优化的超分辨率方法的行为主要由目标函数的选择驱动。最近的工作主要集中在最小化均方重建误差。由此产生的估计具有较高的峰值信噪比，但是它们通常缺乏高频细节，并没有达到较高分辨率期望的逼真度，感觉上不能令人满意。在本文中，我们提出SRGAN，图像超分辨率（SR）的生成对抗网络（GAN）。据我们所知，它是第一个能推出4倍放大因子的照片般逼真的自然图像的框架。为了达到这个目的，我们提出了一个由对抗性损失和内容损失构成的感知损失函数。对抗损失促使我们的解决方案，使用被训练的超分辨率图像和原始照片般逼真的图像之间进行区分鉴别网络的自然图像歧管。此外，我们使用感知相似性驱动的内容损失，而不是像素空间中的相似性。我们的深度残差网络能够从公共基准上严重下的采样图像上恢复真实照片般逼真的纹理。广泛的平均评分（MOS）测试显示使用SRGAN的感知质量的巨大显着增益。用SRGAN获得的MOS分数比用最先进的方法获得的分数更接近于原来的高分辨率图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从其低分辨率（LR）对应物估算高分辨率（HR）图像具有高度挑战性的任务被称为超分辨率（SR）。 SR在计算机视觉研究领域得到了广泛的关注，并具有广泛的应用。  \n",
    "\n",
    "欠定SR问题的不适定性质对于高比例因子特别明显，因为重构SR图像中的纹理细节通常是不存在的。监督SR算法的优化目标通常是恢复的HR图像与真实之间的均方误差（MSE）的最小化。这样做很方便，因为最小化MSE也可以最大化峰值信噪比（PSNR），这是用于评估和比较SR算法的常用度量。然而，MSE（和PSNR）捕捉感知相关差异（如高纹理细节）的能力非常有限，因为它们是基于按像素的图像差异定义的。如图2所示，其中最高的PSNR不一定反映感知上较好的SR结果。超分辨率和原始图像之间的感知差异意味着恢复的图像不像Ferwerda所定义的真实照片。  \n",
    "\n",
    "在这项工作中，我们提出了一个超分辨率的对抗生成网络（SRGAN），我们采用了一个深度残差网络（ResNet）跳过连接和MSE作为唯一的优化目标分歧。 与以前的研究不同，我们使用VGG网络的高层次特征映射和鉴别器来定义一种新的感知损失，鉴别器在感知上很难区分HR参考图像。图1显示了一个与4倍放大因子超分辨的图像逼真图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像超分辨率  \n",
    "\n",
    "最近关于图像的综述文章包括Nasrollahi和Moeslund或Yang等人。 在这里，我们将重点关注单幅图像超分辨率（SISR），而不会进一步讨论从多幅图像恢复HR图像的方法。  \n",
    "\n",
    "基于预测的方法是首先处理SISR的方法之一。尽管这些过滤方法，例如线性，双三次或Lanczos滤波可以非常快速，它们过分简化了SISR问题，并且通常会产生具有过度平滑纹理的解决方案。已经提出了特别关注边缘保存的方法。  \n",
    "\n",
    "更强大的方法旨在建立低分辨率和高分辨率图像信息之间的复杂映射，并且通常依赖于训练数据。许多基于示例对的方法都依赖于LR训练补丁，而相应的HR对手是已知的。早期的工作由Freeman等人提出。SR问题的相关方法来源于压缩感知。在Glasner等人作者利用图像内的各个尺度的补丁冗余来驱动SR。 Huang等人也采用了这种自相似的范式。通过进一步允许小的转换和形状变化来扩展自我字典。顾等人提出了一种卷积稀疏编码方法，通过处理整个图像而不是重叠补丁来提高一致性。  \n",
    "\n",
    "Tai等人为了重建逼真的纹理细节，同时避免了边缘伪影，在之前，将基于梯度曲线的边缘定向的SR算法与基于学习的细节合成相结合。张等人提出了一个多尺度词典来捕捉不同尺度的相似图像块的冗余。为了超级解决地标图像，岳等人检索与网络中具有相似内容的HR图像的相关性，并提出用于对齐的结构感知匹配标准。  \n",
    "\n",
    "邻域嵌入方法通过在低维流形中找到相似的LR训练块并结合它们相应的HR块来进行重构来对LR图像块进行上采样。在Kim和Kwon中，作者强调了邻域方法的趋势，即使用核岭回归来过度拟合和形成一个更为一般的示例对图。回归问题也可以用高斯过程回归，树木或随机森林来解决。在Dai等人大量的补丁专用回归器是学习和在测试过程中选择最合适的回归者。  \n",
    "\n",
    "最近，基于卷积神经网络（CNN）的SR算法表现出优异的性能。在Wang et al作者基于学习迭代收缩和阈值算法（LISTA）将稀疏表示先编码成其前馈网络结构。董等人使用双三次插值来提高输入图像，并端到端地训练三层深全卷积网络，以实现最先进的SR性能。随后显示，使网络能够直接学习升级滤波器可以进一步提高精度和速度方面的性能。 Kim等人用深度递归卷积网络（DRCN）提出了一个高性能的架构，允许远距离的像素依赖性，同时保持模型参数的数量小。与我们的论文特别相关的是Johnson等人和布鲁纳等的著作，他们依靠可感知损失相似的损失函数来恢复视觉上更令人信服的HR图像。  \n",
    "\n",
    "卷积神经网络的设计  \n",
    "\n",
    "在Krizhevsky等人的工作成功后，在许多视觉任务上达到state of the art效果的方法都是通过设计特定的CNN网络结构达到的。  \n",
    "\n",
    "结果表明，较深的网络架构可能难以训练，但有可能显著提高网络的准确性，因为它们允许非常高的复杂性的建模映射。为了有效地训练这些更深层次的网络架构，常常使用batch normalization来抵消内部的协变量转换。更深入的网络体系结构也被证明可以提高SISR的性能，Kim等人制定一个递归的CNN达到state of the art的效果。最近引入了残留块和跳跃连接[的概念，这是减轻深度CNN训练的另一个强大的设计选择。跳跃连接减轻了建模身份映射的网络架构的本质，但是，用卷积内核来表示可能是不重要的。  \n",
    "\n",
    "在SISR的情况下，也显示学习放大滤波器在准确性和速度方面是有益的。 这是Dong等人的一个进步。在采用双三次插值法将图像提供给CNN之前对LR观察进行放大。  \n",
    "\n",
    "损失函数  \n",
    "\n",
    "诸如MSE之类的逐像素损失函数努力处理恢复丢失的高频细节（例如纹理）中固有的不确定性：最小化MSE鼓励寻找通常过度平滑且因此感知质量较差的似然解的像素平均值。不同感知质量的重构以图2中相应的PSNR为例。我们举例说明了图3中最小化MSE的问题，其中多个具有高纹理细节的潜在解被平均以创建平滑重建。  \n",
    "\n",
    "在Mathieu等人和Denton等作者通过使用生成对抗网络（GANs）应用图像生成来解决这个问题。Yu和Porikli用鉴别器损失增加了像素方向的MSE损失，以训练一个网络，该网络能够以大的放大倍数（8×）超解析人脸图像。GANS也被用于Radford等人的无监督表示学习。Li和Wand描述了使用GANs来学习从一个流形到另一个流形的映射，而Yeh等人进行修补。Bruna等人最小化VGG19和散射网络的特征空间的平方误差。  \n",
    "\n",
    "Dosovitskiy和Brox基于神经网络特征空间中计算的欧几里得距离的损失函数结合敌对训练。结果表明，所提出的损失允许在视觉上优越的图像生成，并且可以用于解决对非线性特征表示进行解码的不适定的逆问题。类似于这项工作，约翰逊等人和布鲁纳等提出使用从预训练的VGG网络中提取的特征，而不是低级像素方式的误差测量。具体而言，作者基于从VGG19网络提取的特征图之间的欧氏距离制定损失函数。在超分辨率和艺术风格转移方面，获得了更令人信服的结果。 最近，Li和Wand 也研究了在像素或VGG特征空间中比较和混合色块的效果。  \n",
    "\n",
    "贡献  \n",
    "\n",
    "GANs提供了一个强大的框架，以产生具有高感知质量的看起来合理的自然图像。 GAN程序鼓励朝着包含相片逼真图像的高概率的搜索空间的区域移动的方向重建，因此更接近自然图像，如图3所示。  \n",
    "\n",
    "在本文中，我们描述了第一个非常深的ResNet架构，它使用GAN的概念来形成照片般逼真的SISR的感知损失函数。我们的主要贡献是：  \n",
    "\n",
    "  我们利用PSNR测量的高放大倍数（4倍）和与我们为MSE优化的16块深度ResNet（SRResNet）的结构相似度（SSIM）为图像SR设置了新的技术水平。  \n",
    "\n",
    "  我们提出SRGAN，这是一个基于GAN的网络，针对新的感知损失进行了优化。 在这里，我们用在VGG网络的特征映射上计算的损失代替基于MSE的内容损失，这对于像素空间的变化是更不变的。  \n",
    "\n",
    "  我们通过对来自三个公共基准数据集的图像进行广泛的平均评分（MOS）测试来证实，SRGAN是最新的技术水平，大幅度地估计了具有高放大因子的照片般逼真的SR图像（4×）。  \n",
    "  \n",
    "我们在第2节中描述了网络架构和感知损失。第3节给出了公共基准数据集的定量评估以及视觉插图。本文最后在第4节进行讨论，并在第5节结束语。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在SISR中，目标是从低分辨率$I^{LR}$输入图像估计高分辨率，超分辨率的图像$I^{SR}$。在这里，$I^{LR}$是其高分辨率对应$I^{SR}$的低分辨率版本。高分辨率图像仅在训练期间可用。在训练中，$I^{LR}$通过对$I^{SR}$应用高斯滤波器，然后使用下采样因子 r 进行下采样操作来获得。对于具有 C 色通道的图像，我们通过尺寸为 W×H×C 的实数张量来描述$I^{LR}$，并且分别用 rW×rH×C 来描述$I^{HR}$，$I^{SR}$。  \n",
    "\n",
    "我们的最终目标是训练一个生成函数 G，为给定的 LR 输入图像估计其对应的 HR 图像。为了达到这个目的，我们训练一个生成网络作为一个由$\\theta_G$参数化的前馈CNN $G_{\\theta_G}$。这里$\\theta_G = {W_{1:L};b_{1:L}}$表示L层深度网络的权重和偏差，并通过优化 SR 特定损失函数$l^{SR}$来获得。对于训练图像$I_n^{HR},n = 1，...。。。,N $ 与相应的$I_n^{LR},n = 1，...。。。,N $，我们解决：  \n",
    "\n",
    "公式\n",
    "\n",
    "在这项工作中，我们将特别设计一个感知损失$l^{SR}$作为几个损失组件的加权组合，模拟恢复的SR图像的不同的期望特征。单个损失函数在第2.2节中有更详细的描述。 \n",
    "\n",
    "对抗网络结构  \n",
    "\n",
    "根据Goodfellow等，我们进一步定义了一个鉴别器网络$D_{\\theta_D}$，我们与$G_{\\theta_G}$一起以交替的方式进行优化，以解决对抗最小最大问题：  \n",
    "\n",
    "公式\n",
    "\n",
    "这个公式背后的一般思想是，它允许人们训练一个生成模型 G，目的是欺骗一个可区分的鉴别器 D，该鉴别器被训练成将超分辨图像与真实图像区分开来。 利用这种方法，我们的生成器可以学习创建与真实图像高度相似的解决方案，因此难以用 D 进行分类。这鼓励了存在于自然图像的子空间，流形中的感知上的解决方案。这与通过最小化逐像素误差测量（例如MSE）获得的SR解决方案相反。  \n",
    "\n",
    "在我们非常深的生成器网络 G 的核心，如图4所示，是具有相同布局的 B 残余块。受Johnson等人的启发我们采用了Gross和Wilber提出的区块布局。具体而言，我们使用了两个小的3×3内核和64个特征映射的卷积层，其次是批量归一化层和ParametricReLU作为激活函数。Shi等人提出的利用两个训练的子像素卷积层来增加输入图像的分辨率。  \n",
    "\n",
    "为了从生成的 SR 样本中辨别真实的 HR 图像，我们训练鉴别器网络。架构如图4所示。我们遵循Radford等人总结的架构指南。并使用LeakyReLU激活（α= 0.2），并避免整个网络的最大池化。鉴别器网络被训练以解决公式2中的最大化问题。它包含8个卷积层，其中3×3滤波器内核的数量增加，从VGG网络中的64个到512个内核增加2倍。每次功能数量增加一倍时，使用分段卷积来降低图像分辨率。得到的512个特征图之后是两个密集层和一个最终的 S 形激活函数，以获得样本分类的概率。  \n",
    "\n",
    "感知损失函数  \n",
    "\n",
    "我们的感知损失函数的定义对于我们的生成网络的性能是至关重要的。虽然$l^{SR}$通常基于MSE进行建模，但我们改进了Johnson等人和布鲁纳等。并设计一个损失函数，就感知相关的特性进行评估。我们将知觉损失制定为内容损失$l_X^{SR}$和敌对损失部分的加权和：  \n",
    "\n",
    "公式\n",
    "\n",
    "在下面我们描述可能的选择内容损失$l_X^{SR}$和对抗损失$l_{Gen}^{SR}$  \n",
    "\n",
    "内容损失  \n",
    "\n",
    "以像素为单位的MSE损失计算如下：  \n",
    "\n",
    "公式\n",
    "\n",
    "这是最广泛使用的图像SR的优化目标，其中许多最先进的方法依赖[10,48]。然而，在实现特别高的PSNR的同时，MSE优化问题的解决方案常常缺乏导致感知不足的高频率内容。  \n",
    "\n",
    "区别于依靠像素方面的损失，我们建立在Gatys等人的想法上。并使用更接近知觉相似性的损失函数。我们基于Simonyan和Zisserman中描述的预训练的19层VGG网络的ReLU激活层来定义VGG损失。用$\\phi_{i,j}$表示在VGG19网络中的第 i 个最大层数之前通过第 j 个卷积（在激活之后）获得的特征图，我们考虑给出。然后我们将VGG损失定义为重构图像$G_{\\theta_G}(I^{LR})$和参考图像$I^{HR}$的特征表示之间的欧氏距离：  \n",
    "\n",
    "公式  \n",
    "\n",
    "这里$I_{i,j}$和$H_{i,j}$描述了 VGG 网络中各个特征映射的尺寸。  \n",
    "\n",
    "对抗损失\n",
    "除了迄今为止描述的内容损失之外，我们还将 GAN 的生成元素添加到感知损失中。这鼓励我们的网络倾向于通过尝试欺骗鉴别器网络来支持驻留在自然图像多方面的解决方案。基于所有训练样本上的鉴别器$D_{\\theta_D}(G_{\\theta_G}(I^{LR}))$的概率来定义生成损失$l_{Gen}^{SR}$：  \n",
    "\n",
    "公式\n",
    "\n",
    "这里$D_{\\theta_D}(G_{\\theta_G}(I^{LR}))$是重建图像$G_{\\theta_G}(I^{LR})$是自然 HR 图像的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
