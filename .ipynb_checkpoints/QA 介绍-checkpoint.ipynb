{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA 简介  \n",
    "\n",
    "问答系统与目前主流检索技术有两点不同：首先是查询方式为完整而口语化的问句，其回传的为高精准度网页结果或明确的答案字串。面对这种系统，使用者不需要费心去一一检视搜索引擎回传的网页，对于资讯检索的效率与资讯的普及都有很大帮助。从系统内部来看，问答系统使用了大量有别于传统资讯检索系统自然语言处理技术，如自然语言解析（Natural Language Parsing）、问题分类（Question Classification）、实体识别（Named Entity Recognition）等等。少数系统甚至会使用复杂的逻辑推理机制，来区分出需要推理机制才能够区隔出来的答案。  \n",
    "\n",
    "## 常见 QA 数据集  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/QA/1.jpg?raw=true)\n",
    "<center> **QA 数据介绍** </center >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrQA  \n",
    "\n",
    "### abstract  \n",
    "\n",
    "本文提出使用维基百科作为知识源来解决 open domain QA 问题：关于任何类型问题的答案都是维基百科文章中的文本 span。这种大规模机器阅读的任务将文档检索（查找相关文章）与阅读理解（从这些文章中确定答案）的挑战相结合。我们的方法将基于bigram hash 和 TF-IDF 匹配的搜索组件与经过训练以检测维基百科段落中的答案的多层递归神经网络模型相结合。我们在多个现有数据集上的实验表明：（1）两个模块与现有的方法相比都具有较好的效果;（2）在这些数据上使用远程监督的多任务学习是有效的方法。  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
