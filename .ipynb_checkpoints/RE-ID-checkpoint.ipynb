{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Re-identification: Past, Present and Future  \n",
    "\n",
    "## Abstract  \n",
    "\n",
    "由于 re-id 的应用性和研究意义，目前已经越来越重要。它旨在发现其他相机中感兴趣的人。早期，主要是有关 hand-crafted 算法与小规模的evaluation 的文章。近年来出现了大数据集和利用大数据的深度学习算法。考虑到不同的任务，我们将大多数当前的 re-ID 方法分为两类，image-based和video-based。在这两项任务中，都将 hand-crafted 和深度学习进行评估。此外，描述并讨论了两个与真实世界的应用非常接近的新的 re-id 识别任务，end-to-end re-ID 和 fast re-ID in very large galleries。本文的主要工作如下：1）介绍了人物识别的历史及其与图像分类和实例检索的关系； 2）调查了基于图像和视频的 re-ID 中手工系统和大规模数据方法的广泛选择； 3）描述了大数据集中端到端的 re-id 和快速检索的未来方向； 4）最后简要介绍一些重要而尚未开发的问题。  \n",
    "\n",
    "## 1 INTRODUCTION  \n",
    "\n",
    "。。。  \n",
    "\n",
    "在现代计算机视觉中，人物重识别的任务与旧时代有着相似的见解。在视频监控中，当呈现感兴趣的人（查询）时，人物重识别告诉该人是否在另一个地方（时间）被另一个摄像机观察到。这项任务的出现可以归因于：1）对公共安全需求的不断增加；2）在主题公园，大学校园和街道上广泛存在的大型摄像机网络。这两个原因使得仅依靠人类暴力劳动准确而有效地发现一个感兴趣的人或跨摄像机跟踪一个人是非常耗费时间和精力的。  \n",
    "\n",
    "技术上讲，视频监控中的人物重识别系统可分为三个模块，即人物检测，人物跟踪和人物检索。通常认为，前两个模块是独立的计算机视觉任务，因此大多数 re-ID 作品集中在最后一个模块，即人物检索。本文中，如果没有指定，人物重识别是指人物检索模块。从计算机视觉的角度来看，身份识别系统中最具挑战性的问题是如何在较大的外观变化下正确匹配同一人的两幅图像，如照明，姿态和视点等，这些都具有重要的科学价值。鉴于其研究和应用的重要性， re-ID 的社区正在快速增长，顶级期刊刊登的文章也越来越多(Fig. 1)。  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/1.jpg?raw=true)\n",
    "\n",
    "### 1.1 Organization of This Survey  \n",
    "\n",
    "目前已经有不少 re-ID 的综述文章。本文中，我们主要讨论 re-ID 的视觉部分，这也是 re-ID 的焦点，并且向读者介绍了之前文章中摄像机标定和视图拓扑方法。与以前的 survey 的另一个不同之处在于，我们关注的是目前可用或可能在将来可见的不同 re-ID 子任务，而不是非常详细的技术或体系结构。我们特别强调深度学习方法，端到端的身份认证和超大规模身份认证，这些都是目前流行的话题并反映未来趋势。本 survey 首先在 1.2 节中引入了re-ID 的简要历史，在 1.3 节介绍了与分类和检索的关系，然后，我们分别在第 2 节和第 3 节中描述基于图像和基于视频的人物重识别的先前文献，这两类都有 handcrafted 和 deeply-learned 系统两种方法。在第 4 节中，由于检测，跟踪和再识别之间的关系还没有得到广泛的研究，我们将讨论以前的几个作品并指出未来的研究重点。在第 5 部分中，将引入采用最先进的检索模型的大规模再认证，这也是一个重要的未来方向。第 6 部分将总结其他一些未解决的问题，第 7 部分是结论。  \n",
    "\n",
    "### 1.2 A Brief History of Person Re-ID  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/2.jpg?raw=true)\n",
    "\n",
    "re-ID 研究始于多摄像头跟踪。自那时以来，一些重要的重识别方向已经开发出来。本文中，我们简要介绍一下 re-ID 历史中的一些里程碑（图2）。  \n",
    "\n",
    "**多摄像头跟踪** 在早期，作为一个没有正式提出的术语，person re-ID 与多摄像机跟踪紧密地结合在一起，其中表征模型与不相交摄像机之间的几何校准相结合。1997年，Huang 和 Russell 提出了一种贝叶斯公式，用于估计在其他相机视图中观察到证据的情况下，预测一台相机中物体的表征。表征模型包括多个时空特征，如颜色，车辆长度，高度和宽度，速度和观察时间。  \n",
    "\n",
    "**Multi-camera tracking with explicit “re-identification”** 据我们所知，多像机跟踪中第一次提出“person re-ID”这一术语的工作于2005 年由阿姆斯特丹大学的 Wojciech Zajdel 所发表。在他们的 ICRA'05 论文标题为“Keeping track of humans: Have I seen this person before?”，Zajedel 等人旨在“重新确定一个人离开视野后再重新进入”。在他们的方法中，假定每个人都有一个独特的潜在标签，并且定义一个动态贝叶斯网络来对标签和特征（颜色和空间 - 时间线索）之间的概率关系进行编码。进入人员的 ID 由通过近似贝叶斯推断算法计算的后验标签分布确定。  \n",
    "\n",
    "**The independence of re-ID (image-based)** 一年后的 2006 年，Gheissari 等人仅使用了用于前景检测的 spatial-temporal 分割算法之后的人的视觉线索。基于颜色和显著边缘直方图的视觉匹配由 articulated pedestrian 模型或 Hessian-Affine 兴趣点算子执行，在三个视野有重叠的摄像机拍摄的 44 个人的数据集上进行实验。请注意，尽管 Gheissari 等人使用视频帧设计时空分割方法，特征设计和匹配过程都不使用视频信息，因此我们将它归类为基于图像的 re-ID，这项工作标志着人类再识别与多摄像头跟踪的分离，以及其作为独立计算机视觉任务的开始。  \n",
    "\n",
    "**Video-based re-ID** 最初打算用于视频跟踪，但大多数 re-ID 的作品都专注于图像匹配。在2010年，有两篇作品提出用于多重 re-ID，其中帧是随机选择的。色彩是两个作品中常见的特征，Farenzena 等人另外使用分割模型来检测前景。对于距离测量，都是计算两个图像中边界框之间的最小距离，Bazzani 等人进一步将 Bhattacharyya 距离用于颜色和一般缩影特征。结果表明，每人使用多个帧有效地提高了单帧版本的结果，并且随着所选帧数量的增加，re-ID 的准确性将会饱和。  \n",
    "\n",
    "**Deep learning for re-ID** 2014年，深度学习在图像分类中的成功扩展到了 re-ID，当时 Yi 等人和 Li 等都采用 siamese 网络来确定一对输入图像是否属于同一个 ID。选择 siamese 模型的原因可能是每个身份训练样本的数量是有限的（通常是两个）。除了参数设置的一些变化之外，主要区别在于Yi 在网络中增加了额外的成本函数，而 Li 使用更精细的主体分割。两人实验数据也不一样，因此这两种方法不能直接进行比较。虽然其在小数据集上的表现尚不稳定，但深度学习方法自此成为 re-ID 的流行选项。  \n",
    "\n",
    "**End-to-end image-based re-ID** 虽然大多数作品在实验中使用由固定检测器生成的边界框或人工标点的边界框，但仍有必要研究行人检测器对re-ID 精度的影响。2014年，Xu 等人通过结合检测和 re-ID 分数来解决这个问题，结果表明，在 CAMPUS 数据集中，联合考虑检测和重识别置信度会导致比单独使用它们更高的人物检索准确性。  \n",
    "\n",
    "### 1.3 Relationship with Classification and Retrieval  \n",
    "\n",
    "根据训练和测试类别之间的关系，person re-ID 位于图像分类和实例检索之间（表1）。对于图像分类，每个类都有可用的训练图像，并且测试图像也是是定义好的这些类。对图像检索，通常不存在训练数据，因为提前不知道要查询的内容，数据集也可能包含各种各样的目标。所以训练类别是行不通的，测试数据也是没有见过的。  \n",
    "\n",
    "person re-ID 图像分类相似，有训练数据是存在的，其中图像包含不同的身份。person re-ID 也与实例检索类似，因为测试身份是不可见的：除了训练和测试图像都是行人之外，它们与训练身份没有重叠。  \n",
    "\n",
    "因此，person re-ID  可以利用分类和检索两个方面的成果。一方面，使用训练数据，可以在人的空间中学习识别度量距离或特征嵌入。另一方面，当涉及到检索时，高效的索引结构和散列技术可能有益于大型图库中的 re-ID。在这项调查中，有效学习和有效的检索方法都将被作为未来重要的方向被引入。  \n",
    "\n",
    "## 2 IMAGE-BASED PERSON RE-ID  \n",
    "\n",
    "自 Gheissari 等人在2006年开展工作以来，person re-ID 主要是使用单幅图像进行探索。让我们考虑一个封闭世界的玩具模型，其中 G 是由 N 个图像组成的图库（数据库），表示为 $\\{g_i\\}_{i=1}^N$，它们属于 N 个不同的身份。给定一个测试（查询）图像 q，其身份由下式确定：  \n",
    "\n",
    "$i^* = arg {max}_{i \\in 1,2,...,N}sim(q,g_i)$\n",
    "\n",
    "其中 $i^*$ 是测试数据 q 的 id，sim 是某种相似度函数。  \n",
    "\n",
    "### 2.1 Hand-crafted Systems  \n",
    "\n",
    "从公式 1 中可以看出，简单的 re-ID 系统需要两个组件，即图像描述和距离度量。  \n",
    "\n",
    "#### 2.1.1 Pedestrian Description  \n",
    "\n",
    "在行人描述中，最常用的特征是颜色，而纹理特征不怎么用。有的工作中，行人前景从背景中分割出来，并且为每个身体部分计算一个对称轴。基于身体结构，计算加权颜色直方图（WH），最大稳定颜色区域（MSCR）和 recurrent high-structured patches（RHSP）。WH 为靠近对称轴的像素分配较大的权重，并为每个部分形成颜色直方图。MSCR 可检测稳定的颜色区域并提取颜色，面积和质心等特征。相反，RHSP 是一种捕获经常性纹理补丁的纹理特征。 Gheissari 等人提出了一种空-时分割方法来检测稳定的前景区域。对于局部区域，计算 HS 直方图和边缘直方图。后者编码主要局部边界取向和边缘两侧的 RGB 比率。Gray 和 Tao 在亮度通道上使用 8 个颜色通道（RGB，HS 和 YCbCr）和 21 个纹理 filter，行人被划分为水平条纹。后来的许多作品采用与上述相同的特征。同样，Mignon 等人从RGB，YUV 和 HSV 通道以及水平条纹中的 LBP 纹理直方图建立特征向量。  \n",
    "\n",
    "与上述早期作品相比，近年来手工制作的特征几乎保持不变。在 Zhao 等人的一系列作品中，从每个密集采样的 10×10 小块中提取 32 维 LAB 颜色直方图和 128 维 SIFT 描述符。采用邻接约束搜索来查找图库图像中具有相似纬度的水平条纹中查询补丁的最佳匹配。 Das 等人将 HSV 直方图应用于提出的轮廓的头部，躯干和腿部。Li 等人也从补丁中提取局部颜色描述符，但是使用分层高斯化来聚合它们以捕获空间信息。Pedagadi 等人在使用 PCA 降维之前，从 HSV 和 YUV 空间提取颜色直方图和矩。Liu 等人为每个局部斑块提取 HSV 直方图，梯度直方图和 LBP 直方图。为了提高 RGB 值对光度方差的鲁棒性，Yang 等人为 global 行人颜色描述引入基于颜色描述符的 salient 颜色名称（SCNCD）。还分析了背景和不同色彩空间的影响。Liao 等人提出local maximal occurrence（LOMO）描述符，其中包括颜色和 SILTP 直方图。在同一水平条纹中的 box 经历最大汇集并且在对数转换之前构建三级金字塔模型。Zheng 等人提出为每个本地补丁提取 11 维颜色名称描述符[45]，并通过 Bag-of-Words（BoW）模型将它们聚合成一个全局向量。  \n",
    "\n",
    "除了直接使用低级别的颜色和纹理特征之外，另一个不错的选择是基于属性的特征，可以将其视为中级表示。相信与低级描述符相比，属性对于图像翻译更加稳健。低级颜色和纹理特征用于训练属性分类器。属性加权后，生成的矢量集成在 SDALF 框架中，与其他视觉特征融合。Liu 等人使用带注释的属性来改进潜在的 Dirichlet 分配（LDA）模型，以滤除噪声 LDA 主题。Liu 等人提出以无监督的方式发现一些具有共同属性的行人原型，并根据原型自适应地确定不同查询人的特征权重。最近的一些作品借用外部数据进行属性学习。Su 等人将同一个人但是不同摄像机的二元语义属性嵌入连续的低秩属性空间，使得属性向量对于匹配具有更大的区分性。 Shi 等人建议从现有的时尚摄影数据集中学习多种属性，包括颜色，纹理和类别标签。这些属性直接传送到监控视频下的 re-ID，并取得竞争结果。最近，Li 等人收集了一个具有丰富注释的行人属性大型数据集，以促进基于属性的 re-ID 方法。  \n",
    "\n",
    "#### 2.1.2 Distance Metric Learning  \n",
    "\n",
    "在手工制作的 re-ID 系统中，一个好的距离度量对于它的成功至关重要，因为高维视觉特征通常不会捕获样本差异下的不变因子。这些度量学习方法被归类为监督学习与无监督学习，全局学习与局部学习等。在个人身份识别中，大多数作品属于监督式全局距离度量学习的范畴。  \n",
    "\n",
    "全局度量学习的总体思路是保持同一类的所有向量更接近，同时将不同类的向量进一步分开。最常用的公式是基于 Mahalanobis 距离函数的类，它使用线性缩放和特征空间的旋转来扩展欧几里德距离。两个向量 xi 和 xj 之间的平方距离可以写为，  \n",
    "\n",
    "$d(x_i,x_j) = (x_i-x_j)^TM(x_i-x_j)$\n",
    "\n",
    "其中 M 是一个正半定矩阵，等式 2 可以被表述为由 Xing 等人提出的凸规划问题。  \n",
    "\n",
    "在个人身份识别中，目前最流行的度量学习方法，KISSME 就是基于上述方程式的。在这个方法中，关于一个对 (i,j) 是否相似的决定被表述为似然比。 采用成对差分$(x_{i,j} = x_i - x_j)$，并假定差分空间是零均值的高斯分布。  \n",
    "\n",
    "基于公式2，已经引入了许多其他度量学习方法。在早期，一些经典的度量学习方法针对最近邻分类。Weinberger 等人提出了为目标邻居（匹配对）设置边界并惩罚那些侵入边界（冒名顶替者）的 large margin 最近邻学习（LMNN）方法。这种方法属于有监督的局部距离度量学习。为了避免 LMNN中 遇到过拟合问题，Davis 等人提出信息论度量学习（ITML）作为满足给定的相似性约束和确保学习的度量接近初始距离函数之间的折衷。  \n",
    "\n",
    "近年来，Hirzer 等人提出了放宽积极约束，它为矩阵 M 提供了充分的近似，并且计算成本低得多。除了Mahalanobis距离之外，Chen 等人还增加了一个双线性相似性，这样可以模拟 cross-patch 的相似性。在中，全局距离度量与局部自适应阈值规则相结合，该规则还包含(xi,xj)的正交信息。Liao 等人建议坚持积极的半定义约束，并建议对正面和负面样本进行不同的加权。Yang 等人考虑图像对之间的差异和共同性，并且显示不同对的协方差矩阵可以从相似对的协方差矩阵推断出来，这使得学习过程可以扩展到大型数据集。  \n",
    "\n",
    "除了学习距离度量标准之外，一些作品专注于学习可区分性子空间。Liao 等人提出了将投影 w 学习到一个低维子空间，用与线性判别分析（LDA）类似的方法解决了交叉视图数据。  \n",
    "\n",
    "$J(w) = \\frac {w^TS_bw}{w^TS_w^W}$\n",
    "\n",
    "其中 Sb 和 Sw 分别是类间和类内散度矩阵。然后，使用 KISSME 在得到的子空间中学习距离函数。为了学习 w，Zhang 等人进一步采用 null Foley-Sammon 变换来学习一个满足 0 类内散度和正类间散度的判别性零空间。为了降低尺寸，Pedagadi 等人顺序结合无监督 PCA（主成分分析）和监督局部Fisher 判别分析，保留局部结构。   \n",
    "\n",
    "除了使用 Mahalanobis 距离（方程2）的方法外，还有一些使用其他学习工具，例如支持向量机（SVM）或 boosting。Prosser 等人建议学习一组弱RankSVMs，随后组装成一个更强大的 ranker。此外，structural SVM 也可以被用来在决策级别组合不同颜色描述符。Zhang 等人为每个训练身份学习一个特定的 SVM，并将每个测试图像映射到从其视觉特征推断出的权重向量。Gray 和 Tao 提出使用 AdaBoost 算法来选择和组合许多不同类型的简单特征到单个相似函数中。  \n",
    "\n",
    "## 2.2 Deeply-learned Systems  \n",
    "\n",
    "自 Krizhevsky 等人以来，基于 CNN 的深度学习模型一直很流行。一般来说，社区中通常使用两种 CNN 模型。第一种是用于图像分类和对象检测的分类模型。第二种是使用图像对或 triplets 作为输入的 siamese 模型。深度学习 re-ID 的主要瓶颈是缺乏训练数据。大多数重识别数据集仅为每个身份提供两个图像，例如 VIPeR，因此目前大多数基于 CNN 的重识别方法都集中在 siamese 模型上。在[15]中，输入图像被划分为三个重叠的水平部分，并且这些部分经过两个卷积层加上一个全连接层，将它们融合并输出该图像的向量，使用余弦距离计算两个输出向量的相似度。Li 等人不同之处在于添加了一个补丁匹配层，它将不同水平条纹中的两幅图像的卷积响应相乘，类似于领域的 ACS。后来，Ahmed 等人通过计算交叉输入邻域差异特征来改进 siamese 模型，该特征将来自一个输入图像的特征与另一个图像的邻近位置中的特征进行比较。Wu 等人使用较小尺寸的卷积滤波器加深网络，称为“PersonNet”。Varior 等人将长期短期记忆（LSTM）模块纳入连体网络。 LSTM 依次处理图像部分，以便记忆空间连接以增强深度特征的判别能力。Varior 等人建议在每个卷积层之后插入一个门控函数，以在将一对测试图像馈送到网络中时捕获有效的细微图案。该方法在几个基准上达到了最新的精度，但其缺点也是显而易见的。查询必须在发送到网络之前与每个图库图像配对 - 这是大型数据集中时间效率低下的过程。Liu 等人建议将一个基于 soft attention 的模型集成在一个 siamese 网络中，以自适应地关注输入图像对的重要局部部分；然而，虽然这些作品使用图像对，这种方法也受到计算效率低下的限制。Cheng 等人设计一个三重损失函数，将三个图像作为输入。在第一卷积层之后，针对每个图像划分四个重叠的主体部分并且与 FC 层中的全局部分融合。Su 等人提出了一个三阶段学习过程，其中包括使用独立数据集的属性预测和在具有 ID 标签的数据集上训练的属性三元组损失。  \n",
    "\n",
    "siamese 模型的缺点是它没有充分利用 re-ID 标注。事实上，siamese 模型只需要考虑成对（或三重）标签。告诉图像对是否相似（属于相同的身份），这在 re-ID 中是较弱的标签。另一个潜在的有效策略是使用分类/识别模式，该模式充分利用了再识别标签。在[76]中，来自多个数据集的训练身份联合形成了训练集，并且在分类网络中采用了 softmax 损失。在较大的数据集上，如 PRW 和 MARS，分类模型在没有仔细训练样本选择的情况下可以实现良好的性能。然而，每个 ID 需要有更多的训练数据才能使模型收敛。为了进行比较，本文给出了两种模型的基线结果。在表 2 中，我们在 Market-1501 数据集上实施了识别和验证模型。所有的网络都使用默认的参数设置，并通过 ImageNet 预训练的模型进行微调。图像在被送入网络之前被调整为 224×224。初始学习率设置为 0.001，并在每个时期后减少 0.1 倍。训练在 36 次迭代之后完成。我们可以清楚地看到，识别模型优于验证模型，并且与最近的结果相比，residual-50 模型在 Market-1501 上获得了最先进的再识别精度。  \n",
    "\n",
    "上述作品以端到端的方式学习深度特征，还有一些以低级特征为输入的选择。在[79]中，包括 SIFT 和颜色直方图在内的低级描述符被汇总到每个图像的单个 Fisher Vector 中。混合网络在输入 Fisher 矢量上构建全连接层，并执行线性判别分析（LDA）作为目标函数，以产生具有低级类内差异和高级类间差异的嵌入。 \n",
    "\n",
    "### 2.3 Datasets and Evaluation  \n",
    "\n",
    "#### 2.3.1 Datasets  \n",
    "\n",
    "许多基于图像的重标识的数据集已经发布，一些常用的数据集汇总在表 3 中，最经常使用的是 VIPeR。它包含 632 个身份，每个身份有两个图像。y. 10\n",
    "random train/test splits 用于测试模型是否稳定，并且每个 split 在训练和测试集中都有 316 个不同的身份。这些数据集反映了各种情况，例如，GRID 数据集在一个地铁站收集，iLIDS 在机场到达大厅收集，CUHK01，CUHK02，CUHK03 和 Market-1501 在大学校园里被收集。近年来，可以在几个不同的方面看到收集数据方面的进步。  \n",
    "\n",
    "首先，数据集规模在不断增加。其中很多数据集的规模相对较小，尤其是那些早期的数据集，但最近的数据集（如 CUHK03 和 Market-1501）较大。两者都有超过 1000 个 ID 和超过 10000 个边界框，并且这两个数据集都为训练深度学习模型提供了大量的数据。这就是说，我们必须承认目前的数据量还远远不能令人满意，还非常需要更大的数据集。  \n",
    "\n",
    "其次，边界框倾向于由行人检测器（如 DPM 和 ACF ）生成，而不是手绘。在实际应用中，使用人工绘制数据集边界框是不可行的，因此必须使用检测器。 这可能会导致边界框偏离理想的边界框。在[16]中表明，由于检测器误差（如未对齐），使用检测到的边界框通常会导致与手绘边界框相比的精确度更低。 在[44]中，库中包含了大量错误的检测结果，这在使用检测器时是不可避免的。[44]中的实验表明，随着更多的误检被添加到数据集中，re-ID 的精确度就会不断的下降。因此，有必要研究具有实际缺陷的数据集。  \n",
    "\n",
    "第三，在收集期间使用更多的相机。例如，Market-1501 中的每个身份可以由多达 6 台摄像机捕获。这种设计需要具有良好泛化能力的度量学习方法，而不是在特定相机对之间仔细调整。事实上，一个具有 n 个摄像机网络中，摄像机对的数量是 $C_n^2$，因此从每个摄像机收集标注数据并且训练 $C_n^2$ 个距离度量是不可接受的。    \n",
    "\n",
    "#### 2.3.2 Evaluation Metrics  \n",
    "\n",
    "在评估重识别算法时，通常使用累积匹配特征（cmc）曲线。CMC 表示查询 id 出现在不同候选列表中的概率。不管数据集中匹配到了几个，CMC 只计算第一个匹配到的结果。所以基本上，只有当每个查询真实结果存在时 CMC 才是准确的评估方法。在实践中，当人们更关心查询结果出现在匹配到的结果最前面时，这种测量是可以接受的。  \n",
    "\n",
    "然而，对于研究的完整性，当数据集中存在多个真实结果时，Zheng 等人建议使用均值平均精度（mAP）进行评估。动机是一个完美的身份识别系统应该能够将所有真实的匹配返回给用户。这种情况可能是两个系统同样有能力发现第一个基本事实，但具有不同的检索召回能力。在这种情况下，CMC 没有足够的区分能力，但是可以使用。因此，mAP 与 CMC 一起用于 Market-1501 数据集。  \n",
    "\n",
    "#### 2.3.3 Re-ID Accuracy Over the Years  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/6.jpg?raw=true)\n",
    "\n",
    "在本节中，我们在图 3 中总结了多年来在几个有代表性数据集上重识别的准确率。所呈现的数据集是 VIPeR，CUHK01，iLIDS，PRID 450S，CUHK03 和 Market-1501。我们将目前的方法大致分为两类，即手工制作特征和深度学习。对于每个数据集，显示了在相应年份报告中最高的重识别准确率的代表性方法，从这些结果可以得出三个主要结论。  \n",
    "\n",
    "首先，多年来从六个数据集中可以观察到性能改善的明显趋势。我们观察到 VIPeR，CUHK01，i-LIDS，PRID 450S，CUHK03 和 Market-1501的表现分别增加了 +51.9％，+56.7％，+35.0％，+42.6％，+57.2％ 和 +31.62％。例如，在研究最多的数据集 VIPeR 中，从 2008 年到 2016 年，rank-1 精度从2008 年的 12.0％ 增加到 2015 年的 63.9％，提高了+51.9％。对于 Market-1501 数据集，自 2015 年发布以来，最先进的结果已从 44.42％增加到76.04％，提高了 31.62％。  \n",
    "\n",
    "其次，除了 VIPeR 之外，深度学习方法在其余 5 个数据集上产生了新的 state of the art 的结果。在这 5 个数据集（CUHK01，i-LIDS，PRID 450S，CUHK03 和 Market-1501）上，深度学习的性能优于手工制作的系统。在 CUHK03 和 Market-1501 这两个迄今为止最大的数据集中，我们观察到深度学习的压倒性优势。由于 VIPeR 相对较小，深度学习的优势无法全面体现；相反，手工制定的度量学习在这种情况下可能更有优势。考虑到图像分类和目标检测的情况，很有可能深度学习的系统将在未来几年继续支配再认证任务。  \n",
    "\n",
    "第三，我们推测还有很大的进一步改进空间，尤其是当大型数据集将要发布时。例如，在 Market-1501 数据集中，尽管没有使用多个查询，最佳的 rank-1 准确率为 65.88％，但是 mAP 非常低（39.55％）。这表明尽管在 6 台摄像机中找到第一个真正的匹配（rank-1 准确率）相对容易，但找到较难的样本并提高 MAP 并不是简单的事情。另一方面，虽然我们似乎能够在这些数据集上达到 60％ 到 70％ 的 rank-1 准确率，但我们必须记住，这些数据集在实际应用中只占很小的一部分。事实上，除了[44]之外，还有报道指出，在增加 10倍的数据集上，即使对于表现最佳的方法，rank-1 准确率降低 10 倍。因此，考虑到低 mAP（re-ID recall）和当前数据集的小规模，我们非常乐观的认为基于图像的重识别还有很大的进步空间。  \n",
    "\n",
    "## 3 VIDEO-BASED PERSON RE-ID  \n",
    "\n",
    "论文中，人物重识别大多是单张图片（单张照片）。近年来，由于增加了数据丰富性，导致更多的研究可能性，基于视频的 re-ID 已经变得流行。它与基于图像的重识别共享一个类似的的公式。基于视频的 re-ID 用两组边界框 $\\{q_i\\}_{i=1}^{n_q}$ 和 $\\{g_i\\}_{i=1}^{n_g}$ 替换图像 q 和 g，其中 nq 和 ng 分别是每个视频序列内的边界框的数量。与边界框特征一样重要的是，基于视频的方法更注重多镜头匹配方案和时间信息的整合。  \n",
    "\n",
    "### 3.1 Hand-crafted Systems  \n",
    "\n",
    "2010年的前两个 re-ID 试验都是手工制作的系统。他们基本上使用基于颜色的描述符，并可选地使用前景分割来检测行人。他们使用类似的基于图像的重新识别方法的图像特征，两者主要的区别是匹配函数。如 1.2 节所述，两种方法通常计算两组边界框特征之间的最小欧式距离作为集合的相似度。实质上，这种方法应该被分类为“multi-shot”的人物识别，其中两组帧之间的相似性起着关键作用。这种多重匹配策略被后来的作品采用。在[86]中，基于一组协方差特征，multiple shots 用于训练一个描述性增强模型。在[99]中，SURF 局部特征用于检测和描述短视频序列中的兴趣点，短视频序列依次在 KD 树中索引以加速匹配。在[11]中，生成时空图来标识前景分割的空 - 时稳定区域。随后使用聚类方法计算本地描述以改进匹配性能。Cong 等人采用视频序列中的流形几何结构来构建具有基于颜色的特征的更紧凑的空间描述符。Karaman 等人建议使用条件随机场（CRF）将空间和时间域中的约束合并。在[102]中，使用颜色和选定的人脸图像来建立一个模型，该模型捕捉外观特征以及其随时间变化的模型。Karanam 使用一个人的 multi-shots，并建议将探查特征作为同一人的线性组合。一个身份的多个照片也可以用来增强身体部位对准。在[85]中，为了寻找精确的部分到部分的对应关系，Cheng 等人提出了一种迭代算法，其中由于部分检测器的改进，每次迭代后图形结构的拟合变得更加精确。在[104]中，估计了行人姿势，并且具有相同姿势的框架与更高的置信度相匹配。  \n",
    "\n",
    "上述方法通常基于多个镜头构建外观模型，并且最近的趋势是将时间线索并入模型中。Wang 等人建议使用空 - 间描述符来重识别行人。其功能包括 HOG3D  和 gait energy image（GEI）。通过设计流量能量分布图（FEP），可以检测行走周期，以便使用本地最小/最大值周围的帧来提取运动特征。最后，通过区分视频排名模型选择可靠的时空特征并进行匹配。Liu 等人建议将视频序列解构成表示与某些动作基元相对应的身体动作的一系列单元，从该基元提取Fisher 矢量用于人的最终表示。Gao 等人利用行人的周期性特征，并将行走周期分成若干段。在[110]中，基于密集计算的多方向梯度提出了一种新的时空描述符，并丢弃了在短时间内发生的噪声运动。  \n",
    "\n",
    "在匹配视频时，距离度量学习也很重要。 在[111]中，提出了一组验证方法，其中采用 transfer ranking 来判断查询是匹配到的是相同身份的图像之一。 在[89]中，所提出的局部匹配模型的多重延伸使得最佳匹配对的距离最小化并且减少了交叉视图变换的数量。Zhu 等人同时提出学习视频内和视频间距离度量，以使视频表示更加紧凑并区分不同身份的视频。  \n",
    "\n",
    "### 3.2 Deeply-learned Systems  \n",
    "\n",
    "在基于视频的 re-ID 中，数据量通常比基于图像的数据集大，因为每个 tracklet 包含多个帧（表4）。  \n",
    "\n",
    "基于视频和基于图像的 re-ID 之间的基本区别在于，对于每个匹配单元（视频序列）而言，多个图像应该采用多个匹配策略或单个匹配策略。较老的作品一般使用多重匹配策略，这会导致较高的计算成本，并且可能在大型数据集上存在问题。另一方面，pooling-based 方法将帧级特征聚合成具有更好可扩展性的全局向量。结果，当前基于视频的重识别方法通常涉及合并步骤。这个步骤可以是 max/average pooling，或通过全连接的层学习。在 Zheng 等人的系统中，时间信息没有被明确地捕获；相反，一个 id 的 frames 作为训练数据，通过 softmax 训练分类模型。frames 特征通过 max pooling ，从而在三个数据集上产生有竞争力的准确率。这些方法被证明是有效的，但还有很大的改进空间。关于这一点，重认证的社区可以借鉴 action/event 识别。例如，Xu 等人建议将 CaffeNet 的第 5 卷积层中的列特征聚合成 Fisher 矢量或 VLAD，直接进行 CNN 特征转移。Fernando 等人提出了一个 learning-to-rank 的模型来捕捉视频中帧特征随着时间的推移如何演变，这产生了视频范围内时间动态的视频描述符。Wang 等人将多级编码层嵌入到 CNN 模型中并产生不同序列长度的视频描述符。  \n",
    "\n",
    "另一个好的做法是在最终表示中注入时间信息。在手工制造系统中，Wang 等人和刘等人在 iLIDS-VID 和 PRID-2011 数据集上使用纯空时特征并报告了有竞争性的准确率。然而，在[21]中，表明时空特征在 MARS 数据集上不具有足够的辨别力，因为许多行人在相同的摄像机下共享类似的运动，并且同一人的运动特征在不同相机下可能不同。在[21]中提出的观点是，外观特征在大规模视频再认证系统中至关重要。在文献[114]中，通过 CNN 模型从连续的视频帧中提取特征，然后传到 recurrent final layer，以便允许时间步之间的信息流。然后使用最大或平均池合并特征，以生成视频的外观特征。所有这些结构都被整合到一个 siamese 网络中。 [120]中使用了类似的体系结构，他们的区别是 two-fold ，首先，在[120]中使用了特定类型的 RNN，门控重发单元（GRU）。其次，[114]采用识别损失，这有利于损失收敛和性能改进。虽然这两个作品采用 siamese 网络进行损失计算，但 Yan et al 和郑等人使用将每个输入视频分类为各自身份的识别模型。在[115]中，手工制作的低级功能（如颜色和LBP）被送入多个 LSTM，LSTM 输出连接到 softmax 层。在动作识别中，Wu 等人提出从视频中提取外观和时空特征，并建立一个混合网络来融合这两种特征。在本文中，我们注意到外观和时空模型的区别组合可能是未来视频 re-ID 研究的有效解决方案。  \n",
    "\n",
    "### 3.3 Datasets and Evaluation  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/7.jpg?raw=true)\n",
    "\n",
    "存在多个 Re-ID 数据集，例如ETH，3DPES，PRID-2011，iLIDS-VID 和 MARS。表 4 总结了这些数据集的一些统计数据。ETH 数据集使用一台移动摄像机。它包含三个序列，并提供每个序列的多个图像。这个数据集相对容易，multi-shot 场景的 re-ID 准确率接近100％。3DPeS 数据集由 8 台非重叠户外相机收集。虽然视频已发布，但此数据集通常用于 single-shot re-ID。PRID-2011 和 iLIDSVID 的相似之处在于两个数据集都由 2 台摄像机捕获，每个身份有 2 个视频序列。iLIDSVID 在室内场景下拍摄了 300 个身份。 PRID-2011 每个相机在户外拍摄了 385 和 749 个身份，并且在这个数据集中有 200 个身份在两个相机中被观察到。在测试期间，根据[105]的提案，PRID-2011 使用了 178 个身份。一般认为，由于遮挡非常严重，iLIDS-VID 比 PRID-2011 更具挑战性。最近发布的 MARS 数据集，是一个大型视频 reID 数据集，包含超过 20000 个视频序列中的 1261 个身份，使用 DPM 检测器和 GMMCP 跟踪器生成。由于最近才发布，我们没有提供关于 MARS 数据集结果的广泛总结。图 4 给出了对三个有代表性的视频（多镜头）re-ID 数据集（即 ETHZ，iLIDS-VID，PRID-2011）的最新结果的评估。得出两个主要结论：  \n",
    "\n",
    "首先，ETHZ 数据集已达到其饱和性能。2015 年，Lisanti 等人和马丁内尔等人报告 rank-1 accuracy 接近 100%。在[124]中，每个序列使用 5 个图像，ETHZ 序列 1, 2 和 3 的 rank-1 accuracy 分别为 99.8％，99.7％ 和 99.9％。每个序列 10 帧的结果更高，达到 100％。主要原因是 ETHZ 数据集具有相对较少的身份，并且由于仅使用一个移动照相机而导致图像方差较低。这可能是第一个重识别数据集，几乎可以实现其最初目标。  \n",
    "\n",
    "其次，有效的视频再识别仍在 iLIDS-VID 和 PRID-2011 数据集上进行研究。自推出以来，我们观察到他们 rank-1 准确性（包括 ETHZ 数据集）的明显改善。对于 iLIDS-VID，Wang 等人的 rank-1 准确率为 23.3％。在 PRID-2011 上，Wang等人的 rank-1 准确率为 19.0％，两年后，Zheng等人使用在 MARS 数据集上进行微调的 CNN  max pooling，将这一分数提高 58.3％。  \n",
    "\n",
    "第三，深度学习方法在基于视频的身份识别中产生绝对优异的准确率。在 iLIDS-VID 和 PRID-2011 数据集上，表现最好的方法都是基于卷积神经网络，并可选择的插入循环神经网络。与基于图像的 reID 相比，训练数据的数量在视频重识别中明显更大。MARS 提供了超过 500k 的训练数据，而 MarketS-1501 数据集中的 13k 则是 MARS 的延伸。利用这些训练数据，不仅对基于视频的重识别，而且对基于图像的数据集进行识别网络的训练也是可行的。我们还注意到，虽然 MARS 数据集的 rank-1 准确率达到了 68.3％，但其 mAP 仍然较低（49.3％），并且在评估每个摄像机对的性能时，性能进一步降低。因此，我们认为视频再识别技术的研究仍有很大的改进空间。  \n",
    "\n",
    "## 4 FUTURE: DETECTION, TRACKING AND PERSON RE-ID  \n",
    "\n",
    "### 4.1 Previous Works  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/9.jpg?raw=true)\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/10.jpg?raw=true)\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/11.jpg?raw=true)\n",
    "\n",
    "尽管人的身份识别来源于多摄像头跟踪，但现在作为一个独立的研究主题进行研究。在这次调查中，我们认为重识别是未来的一个重要方向，将行人检测和追踪作为一种情景加入，而是扮演更加独立的角色。具体来说，我们考虑一个端到端的重识别系统，它将原始视频作为输入，并集成行人检测和跟踪以及重识别。  \n",
    "\n",
    "直到最近，大多数 reID 作品都基于两个假设：第一，给出了行人边界框的图库；其次，边界框是手绘的，具有完美的检测质量。但是，在实践中，这两个假设并不成立。一方面，图库的大小随检测器阈值而变化。较低的阈值会产生更多的边界框（较大的图库，较高的召回率和较低的精度），反之亦然。当检测召回/精度因阈值不同而发生变化时，重识别精度不会保持稳定。另一方面，当使用行人检测器时，边界框通常会存在检测错误，例如未对准，漏检和错误警报。此外，当使用行人追踪器时，追踪错误可能导致轨迹内的异常帧，即具有不同身份的背景或行人。因此，行人检测和跟踪的质量可能会直接影响重识别的准确性，这在再识别社区中很少讨论。下面我们将回顾一下这方面的几部作品。  \n",
    "\n",
    "在最初尝试解决第二个问题时，引入了几个数据集，即 CUHK03，Market-1501 和 MARS。这些数据集不会假定完美的检测/跟踪输出，并且更接近实际应用。例如，Li 等人表明，在 CUHK03 上，使用检测到的边界框的重识别精度低于用手绘边界框获得的重识别精度。后来的作品也报道了这一结果。这些发现与实际应用密切相关。在 MARS 上，跟踪错误（图 8）以及检测错误被展示出来，但跟踪错误将如何影响重识别的准确度仍然未知。  \n",
    "\n",
    "尽管数据集通过引入检测/跟踪错误而取得了进展，但它们并未明确评估检测/跟踪如何影响重识别，这中评估可以为最终如何在大量现有作品中选择检测器/跟踪器提供重要见解。据我们所知，Xu 等人提出了关于端到端人员重识别的第一项工作。他们使用术语“commonness”来描述图像边界框如何类似于行人，而术语“uniqueness”表示图库边界框和查询之间的相似性。通用性和唯一性由它们的产品以指数函数进行融合。此方法通过消除虚假背景检测的影响起作用。尽管 Xu 等人考虑检测对 reID 的影响，其局限性在于缺乏全面的基准测试和对图库动态问题的考虑。  \n",
    "\n",
    "2016年，Xiao 等人和 Zheng 等人同时引入基于大规模数据集的端到端身份认证系统。这两个作品采用原始视频帧和查询边界框作为输入（图 5）。需要先对原始帧执行行人检测，然后生成的边界框形成重识别库，然后，利用经典的 reID。这个过程被称为“人员搜索”，不再局限于重识别（图5（b））：它同时关注检测模块（图5（a））。这条管道的一个非常重要的方面是，如果有相同的重识别特征，更好的行人检测器往往会产生更高的重识别精度。另一个有趣的话题是行人检测是否有助于 person re-ID。在[18]，[77]中，检测可信度被整合到最终的重识别分数中。在[128]中，行人检测和 re-ID 在 CNN 模型中被联合考虑，类似于 Faster R-CNN，而在[77]中，ID-discriminative embedding（IDE）根据 R-CNN 模型预先训练的 CNN 模型进行行人检测。这些方法提供了关于弱标记检测数据如何帮助提高重识别准确性的初步见解。  \n",
    "\n",
    "尽管如此，在所谓的“端到端”系统中，没有提及行人跟踪，也不知道任何现有的作品/数据集解决跟踪对重识别的影响。该工作将其视为将检测，跟踪和检索集成到一个框架中的“终极”目标，并评估每个模块对整体 reID 性能的影响。 因此，本调查要求提供大规模数据集，以提供边界框注释以用于三项任务。  \n",
    "\n",
    "### 4.2 Future Issues  \n",
    "\n",
    "#### 4.2.1 System Performance Evaluation  \n",
    "\n",
    "适当的评估方法是一个关键而又很棘手的话题。一般来说，没有单一的“正确”协议，特别是对于探索不足的端到端 reID 任务。基于所使用的特定检测器/跟踪器及其参数，端到端的重识别系统与动态图库中大多数当前的重识别研究不同。此外，如何评估个人身份识别方案中的检测/跟踪性能，目前还很不明确。因此，这项调查提出了两个方面的系统评估问题。  \n",
    "\n",
    "首先，使用有效的评估指标对 reID 中的行人检测和跟踪是至关重要的。评估协议应该能够以现实和公正的方式对探测器/跟踪器的性能进行量化和评级，并提供重识别准确性的信息。例如，行人检测主要采用 log-average miss rate (MR)，这是在 precision range of FPPI (false positives per image)进行平均得到的。有些还使用 PASCAL VOC 中的 average precision (AP)。Dollar 等人认为，在某些任务（如汽车应用）中，使用针对 FPPI 的 miss rate 优于 precision recall curves，因为可接受的 FPPI 可能存在上限。与行人检测的汽车应用相反，人员重识别旨在找到一个不一定关心误报率的人。所以基本上我们可以使用 miss rate and average precision 来评估用于人员重识别中的行人检测。  \n",
    "\n",
    "AP/MR 计算中的一个重要参数是 intersect over union（IoU）分数的相交。如果其与真值边界框的 IoU 得分大于阈值，则检测到的边界框被认为是正确的。通常，阈值设置为 0.5，然而 Zhang 等人在各种 IoU 分数下研究“完美单帧检测器”和自动检测器之间的区别。KITTI 基准要求汽车检测的 IoU 为0.7，而行人为 0.5。对于人员重识别，这个问题是可以接受的。一些关于它的线索依然存在，如果我们更接近[77]中的结论，我们应该意识到使用较大的IoU 得分（例如0.7）与较低的 IoU 相比是更好的评估标准。图 6 显示了 PRW 数据集上的检测准确性（AP）和重识别准确性(rank-1 or mAP)之间的关系。在 IoU = 0.7 下的两个任务之间明显存在线性关系，而在 IoU = 0.5 下存在分散的情节。因此检测器和识别器之间的相关性与更大的 IoU 更加一致。尽管如此，它还远远不能令人满意。  \n",
    "\n",
    "考虑到边界框定位质量对于重识别精度非常重要，在评估检测器质量时要研究 IoU 阈值并查看它是否符合重识别的准确性是一个好主意。我们的直觉是，较大的 IoU 标准得到更好的定位结果，但是必须有一定的限制，因为当 IoU 变大时探测器性能的差异趋于减小。探索[138]中提出的从 0.5 到 1 的IoU平均召回率（AR）的用法并且将 AR 用于不同数量的检测器阈值。这样的评估指标考虑了召回和定位，并且我们推测它可能在 reID 中特别具有信息性，其中行人检测召回和边界框质量是至关重要的  \n",
    "\n",
    "虽然至少有一些线索可以指导行人检测的评估，但如何评估个人身份识别下的跟踪功能在很大程度上是未知的。在多目标跟踪（MOT）基准中，使用了多种评估指标，包括多目标跟踪精度（MOTP），主要是跟踪目标（轨道被追踪覆盖的地面真实人数的百分比）结果为至少 80％），false positive 总数（FP），ID switches 总数（IDS），轨迹碎片总数（Frag），每秒处理的帧数（Hz ）等等。有些指标可能是有限的指示能力，如处理速度，因为跟踪是一个离线步骤。对于 reID，我们预计跟踪精度是至关重要的，因为在 tracklets 中存在影响池化效果的异常图像是不理想的。我们还推测，80％ 可能不是用于评估重识别中 MT 的最佳阈值。正如[105]所建议的那样，在步行周期内提取特征是一种很好的做法，因此产生长的跟踪序列可能不会给 reID 带来太多的改进。未来，一旦用来评估跟踪和重识别的数据集发布，一个紧迫的问题就是设计适当的度量来评估不同的跟踪器。  \n",
    "\n",
    "评估程序中的第二个问题涉及整个系统的重识别准确性。与图库固定的传统 reID 相反，在端到端重识别系统中，图库随检测/跟踪阈值而变化。更严格的阈值表示更高的检测/跟踪信心，因此图库较小，背景检测较少，反之亦然。此外，图库的大小对 reID 的准确性有直接影响。让我们以一个极端案例为例。当检测/跟踪阈值非常严格时，图库可能非常小，甚至真实数据也被排除在外。在另一个极端情况下，当检测/跟踪阈值被设置为一个非常宽松的值时，图库将会非常大，并且包含多个背景检测，这可能对 re-ID 产生负面影响，如[44]所示。因此，可以预见的是，过于严格或过于宽松的阈值导致劣质图库，并且 reID 的评估反应了 reID 准确率与图库大小之间的动态变化。在[77]中，郑等人针对每个图像的不同检测次数绘制 rank-1 准确度和 mAP，观察到曲线先上升到峰值然后下降。在 PRW 数据集中，峰值位于每个图像 4-5 个检测点处，其可以用作每个图像的平均行人数量的估计。在[128]中，采用了类似的协议，即将 rank-1 匹配率相对于检测召回作图，并在召回= 70％ 时达到其最大值。当召回进一步增加时，错误检测的普遍性将损害重识别的准确性。还可以探索其他一些想法，例如，根据 FPPI 绘制 reID 的准确性。请记住，图库的大小取决于检测器的阈值，未来可以设计其他新的评估指标，这些指标是信息性和无偏见的。  \n",
    "\n",
    "我们还指出了端到端 reID 系统中的另一种评估协议。在实践中，当呈现查询边界框/视频序列时，尽管可以在特定帧中定位身份并且通过行人检测/跟踪来告知其坐标，但是系统仅知道哪个帧身份重新出现在查询人的具体位置，然后可以通过高效率的人工找到。实质上，确定被查询人出现的确切帧比“检测/跟踪+重新识别”任务相对更容易，因为检测/跟踪错误可能不会产生大的影响。在这种情况下，reID 的准确度应该高于标准的 reID 任务。而且，mean\n",
    "average precision 可以用于检索的视频帧。由于这项任务不需要非常精确地定位人员，因此我们可以使用宽松的检测器/提议或跟踪器来提高帧级调用。可以学习探测器/proposals 来定位一个宽松的 IoU 限制的行人区域，并更加重视匹配，即从较大的边界框/空间-时间管中找到特定的人。  \n",
    "\n",
    "#### 4.2.2 The Influence of Detector/Tracker on Re-ID  \n",
    "\n",
    "人员身份识别来自行人追踪，如果他们被确定为具有相同身份，则来自多个摄像头的踪迹相关联。这一系列研究将重识别作为跟踪系统的一部分，并且不评估定位/跟踪精度对重识别准确性的影响。但是，即使 reID 独立以来，大多数研究都是在手绘图像包围盒上进行的，这是一种难以满足实际情况的理想情况。因此，在端到端的身份识别系统中，重要的是要了解检测/跟踪对重识别的影响，并提出检测/跟踪/数据可以帮助重识别的方法。 \n",
    "\n",
    "首先，行人/跟踪误差的确会影响重识别的准确性，但内在机制和可行解决方案仍然是有待解决的。错误检测（图7）可能会导致行人失准，尺度变化，部分失踪，最重要的是误报和错误检测，这会影响到身份识别性能并带来新的挑战。  \n",
    "\n",
    "一些 reID 作品会将检测/追踪错误考虑在内。Zheng 等人建议融合 local-local 和 global-local 匹配来解决严重遮挡或部分缺失的 reID 问题。Xu 等人通过将 GMM 编码的描述符与先前的分布进行匹配来计算“共同性”分数。该分数可用于消除不包含人体或不能提供良好的人体定位的误报。以类似的方式，Zheng 等人提出将检测器置信度（在平方根之后）整合到 reID 相似性分数中，据此重新对边界框进行排序。这些作品在发生错误后解决检测错误。尽管如此，在早期阶段可能会避免检测/跟踪错误。例如，在 Xiao 等人设计的网络中，在 fast R-CNN 子模块中添加了定位损失。它规定了对于有效的身份识别系统至关重要的定位质量。  \n",
    "\n",
    "未来的调查需要揭示人员重识别对检测/跟踪质量的依赖性。由于开发没有错误的检测器/跟踪器的想法太过于理想化，我们主张研究如何将检测置信度集成到 re-ID 分数中，即如何通过有效识别异常值来纠正错误，以及如何训练上下文不依赖于检测到的边界框的模型。例如，使用聚类算法来滤除 tracklet 中的不一致帧可以有效净化跟踪序列。在另一个例子中，检测到的边界框可以被放大以包括可能丢失的身体部位并学习区分性特征。  \n",
    "\n",
    "其次，我们应该意识到，如果设计得当，检测和跟踪可能有助于重识别。在[77]中，在 R-CNN 模型上进行微调的 IDE 网络被证明比直接在 ImageNet 预训练模型上进行精细调整的 IDE 网络更有效。这说明了在行人检测中使用过量标记数据的重要性，即具有 ID 注释和误报检测的行人。在[128]中，端到端网络集成了背景检测的损失，这被假定为提高了学习嵌入的判别能力。将检测分数整合到 re-ID 相似性中也可以被视为检测有助于重识别的替代方案。  \n",
    "\n",
    "看起来行人检测/跟踪可能有助于重识别或者相反，但是如果我们考虑通用图像分类和细粒度分类的类比，我们可能会想到一些线索。例如，在细粒度数据集上微调 ImageNet 预先训练的 CNN 模型是更快收敛和更高细粒度识别准确率的有效方法。通过向 RCNN 部分反向传播 reID 损失来联合训练行人检测和重识别模型也是一个好主意。能够区分不同的身份可能有利于从背景中区分行人的任务，后者也可能对前者有所帮助。  \n",
    "\n",
    "可以探索的想法之一是使用无监督的跟踪数据。在视频中，追踪行人并不是一件困难的事情，尽管跟踪错误是不可避免的。面部识别，颜色和非背景信息是改善跟踪效果的有用工具，如哈利波特的掠夺者地图。在跟踪序列中，人的外观可能在一定程度上经历差异，但可以预期，大部分边界框是同一个人。在这种情况下，每个轨迹代表一个人，其中包含一些嘈杂但粗略可用的训练样本。因此，我们可以利用 racking results 来训练行人验证/识别模型，从而减轻对大规模监督数据的依赖。作为另一个有前景的想法，值得尝试使用自动编码器或生成对抗网络（GAN）。使用这样的无监督网络直接学习人员描述符以帮助解决人身份识别中的数据问题也是有趣的。  \n",
    "\n",
    "## 5 FUTURE: PERSON RE-ID IN VERY LARGE GALLERIES  \n",
    "\n",
    "近年来，身份认证社区的数据量显著增加，例如，VIPeR 和 iLIDS 中的数百个图库图像与 PRW 和 LSPS 中的图像数量相比显著增加导致了深度学习方法的优势。然而，显然目前的数据集还远未达到实际的规模。假设在具有 100 个摄像机的区域级监视网络中，如果每秒使用一个视频帧用于行人检测，并且每帧产生平均 10 个边界框，则运行该系统12小时将产生 $43.2 × 10^6$ 个边界框。但据我们所知，以前没有任何作品报道过在这样一个大型图库里 reID 的表现。似乎文献中使用的最大的图库是 500k，证据表明，与具有 19k 图库的 Market-1501 相比，MAP 下降了 7％ 以上。此外，在[44]中，近似最近邻搜索被用于快速检索，但代价是精确度受损。  \n",
    "\n",
    "从研究和应用的角度来看，非常大的图库中的人物再认证应该是未来的关键方向。应该尝试改善准确率和效率问题。  \n",
    "\n",
    "一方面，健壮和大规模的描述符和距离度量的学习更重要。这与目前的研究一致。在大规模图像识别之后，人员重识别将进行大规模评估。尽管目前的方法在非常有限的时间窗口内解决了一对或多对摄像机之间的重识别问题，但长期以来摄像机网络中的鲁棒性尚未得到充分考虑。在[36]，[146]中，摄像机网络中的 reID 一致性使用成对的匹配准确率进行优化，但测试数据集（WARD 和 RAiD）只有 3 和 4 个摄像机并少于 100 个身份。在具有 n 个相机的网络中，相机对的数量是 $O(n^2)$。考虑到较长的记录时间和缺乏注释数据，通常不能以成对方式训练距离度量或 CNN 描述符。因此，培养适应各种照明条件和摄像机位置的 global re-ID 模型是重中之重。为实现这一目标，一种选择是设计无监督描述符，其目的是寻找视觉上相似的人并将视觉上不相似的人视为错误匹配，但是无监督的方法可能倾向于照明变化。  \n",
    "\n",
    "另一方面，效率是这样一个大规模环境中的另一个重要问题。尽管在小型数据集中几乎可以忽略计算时间，但在我们的实验中，在使用 3.1GHz Intel Xeon E5-2687w v3（10个内核），64GB 内存的服务器上使用 MATLAB 2014 时，计算需要 8.50s 100-dim 浮动矢量与数量为 1000 万的 100-dim 矢量之间的距离。如果我们使用从 CaffeNet 和 C++ 编程中提取的 4,096 维浮点向量，所用的时间会显着增加到 60.7s，包括 33.2s 的距离计算和 26.8s 的数据从磁盘加载。显然，根据特征尺寸和图库大小，查询时间显着增加，这对于实际使用而言是不希望的。据我们所知，以前的 person re-ID 很少关注效率问题，因此缺乏有效的解决方案，但幸运的是，我们可以求助于图像检索社区寻求答案，本调查提供了两个可能的方向。    \n",
    "\n",
    "**Inverted index-based** 倒排索引是基于 Bag-of-Words（BoW）检索方法的数据结构。基于局部描述符的量化结果，倒排索引具有 k 个条目，其中 k 表示码本大小。索引结构因此具有 k 个条目，并且每个都附加到倒排列表，其中本地描述符被索引。基线倒排索引的结构如图 9 所示。将索引描述符的图像 ID 和词频（TF）存储在一系列作品中，可以存储许多其他元数据，例如二进制签名，特征坐标等。对于实例检索中倒排索引的基本知识和最新进展，我们引用读者最近的一项调查[19]。  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/12.jpg?raw=true)\n",
    "\n",
    "在 person re-ID 中，局部描述符的使用非常流行。颜色和纹理特征通常从局部补丁中提取。虽然以前的一些作品使用了复杂的匹配算法，但最好使用大图库下的倒排索引来加速匹配过程。通常需要码本来将局部描述符量化为视觉单词，并且由于局部描述符是高维的，因此需要较大的码本来减少量化误差。 在这些情况下，倒排索引即可使用，这在很大程度上节省了存储器成本，并且如果适当使用，可以具有与无量化自适应情况相同的准确度。  \n",
    "\n",
    "**Hashing-based** Hashing 一直是一个广泛研究的近似最近邻搜索解决方案，其目的在于减少当图库较大或距离计算成本较高时查找确切最近邻的成本。在里程碑式的工作频谱 hash 之后，学习 hash 在社区中很受欢迎。它指的是学习 hash 函数，y = h（x），将向量 x 映射到紧致 y，并且旨在保持搜索过程的效率的同时在秩列表中找到真正的最近邻居。一些经典的学习哈希方法包括 product 量化（PQ），迭代量化（ITQ）等。这两种方法在训练中都是高效的并且具有合理的检索精度。它们不需要标记数据，因此当大量训练数据可能不可用时适用于重识别任务。  \n",
    "\n",
    "Supervised hashing 的另一个应用是图像检索，这是本节的重点。哈希函数通过深度学习网络端到端地学习，该网络输出给定输入图像的二进制向量。为了充分利用通用实例检索数据集中缺乏的训练数据，这一行着重于几个图像分类数据集，如 CIFAR-10 和 NUS-WIDE。在 person re-ID，应用场景与图像检索的 deep hashing 很好地吻合。在大型图库中，非常需要高效但准确的哈希方法，这是一种在重识别中较少探索的方向。如表 1 所示，训练类别在 reID 数据集中是存在的，而测试过程是一项标准的检索任务，所以当前受监督的哈希方法很容易被用于重识别。我们发现的唯一相关工作是[158]，该算法在一个 triplet-loss CNN 网络中学习哈希函数，并通过正则化来强化邻接一致性。该方法在 CUHK03 数据集上进行了测试，该数据集在每个测试分组中包含100 个身份，因此在这个意义上，超大图库的性能评估仍然不足。因此，本次调查需要非常大的重识别数据集，以评估重识别方法和可扩展算法的可扩展性，尤其是那些使用哈希编码的算法，以进一步将此任务推向实际应用。  \n",
    "\n",
    "## 6 OTHER IMPORTANT YET UNDER-DEVELOPED OPEN ISSUES  \n",
    "\n",
    "### 6.1 Battle Against Data Volumn  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/1/13.jpg?raw=true)\n",
    "\n",
    "标注大规模数据集一直是视觉社区的一个焦点。这个问题在个人身份识别中更具挑战性，因为除了绘制行人的边界框之外，还必须为他分配一个 ID。ID 分配不是微不足道的，因为在行人首次出现后，行人可能会重新进入视野（FOV）或长时间进入另一个观察摄像机。这使得协作标注变得困难，因为两个协作者在标注 ID 上进行通信的成本很高。这些困难部分解释了为什么当前数据集中 为什么每个 ID 的图片数量都非常有限。过去两年已经见证了一些大规模数据集的发布，例如 Market-1501，PRW，LSPS 和 MARS，但从实际应用的角度来看，它们还远远不够满意。在这项调查中，我们相信两种替代策略可以帮助绕过数据问题。  \n",
    "\n",
    "首先，如何使用来自追踪和检测数据集的注释尚处于探索阶段。与 reID 相比，跟踪和检测标注在人员重新进入 FOV 时不需要进行 ID 分配：大部分工作都花费在边框绘制上。在[77]中，显示在 R-CNN 阶段添加更多的行人和背景训练数据有益于后面 IDE 描述符的训练。在[50]，[75]中，来自独立数据集的属性注释被用来表示 reID 图像。由于这些属性可以通过工作人员之间的协作进行注释，并具有很好的泛化能力，因此它们也是重识别数据不足的替代方案。因此，缺乏训练数据时，外部资源对训练身份识别系统很有价值。  \n",
    "\n",
    "除了第 4.2.2 节提到的预训练/无监督策略之外，一种新颖的解决方案是从未标记的数据中检索出可能被视为度量学习/ CNN 训练中的“true positives”的 hard negatives。这种策略已经在对象分类中进行了评估，其中一小部分标签在训练之前受到干扰。它可以有效地扩大训练集，同时降低模型过拟合的风险。我们的初步实验表明，这个方向在基线方面有了不错的改进。  \n",
    "\n",
    "第二种策略是迁移学习，将经过训练的模型从源域转移到目标域。以前，监督学习需要大量标记数据，这限制了重识别系统扩展到其他摄像机。在文献[160]中，提出了一种无监督的主题模型，用于发现用于 re-ID 匹配的图像块。在文献[161]中，提出了一种弱监督方法，该方法需要来自其他重识别数据集的全注释以及目标场景中捕获的少量样本。在[162]，[163]中，提出了无监督转移学习，其中目标数据集未标记。 Ma 等人采用跨域排序 SVM，而 Peng 等人将转移问题表述为字典学习任务，该任务学习共享不变潜变量并且偏向于目标数据集。这些方法表明，从源头学习 reID 模型是可行的，并且从无监督数据中挖掘出区分线索是有益的。将 CNN 模型转换为其他 re-ID 数据集可能会更加困难，因为深层模型可以很好地适应来源。Xiao 等人收集多个源再识别数据集并联合训练目标数据集的识别模型。根据我们的经验，使用现成的度量学习方法也可以在一定程度上纠正转移效应，但无监督转移学习对于深度学习模型仍然是一个公开问题。  \n",
    "\n",
    "### 6.2 Re-ranking Re-ID Results  \n",
    "\n",
    "重识别过程（图5（b））可以看作是一个检索任务，其中重新排序是提高检索准确性的重要步骤。它指的是重新排序可以发现重新排序知识的初始排序结果。关于搜索重排方法的详细调查，我们将读者引荐给[164]。  \n",
    "\n",
    "此主题存在一些以前的作品。重新排序可以在循环中完成，也可以完全自动执行。当涉及在线人员标签时，Liu 等人提出允许用户从初始等级列表中提供简单的否定的以及可选地提供的一些硬性否定的后排序优化（POP）方法。稀疏的人体反馈可以实现查询人的即时自动区分特征选择。在一个改进中，Wang 等人设计人体验证增量学习（HVIL）模型，该模型不需要任何预先标记的训练数据，并从人类反馈累积学习以提供实例模型更新。许多渐进式学习的 HVIL 模型被合并为一个单一的整体模型，以便在人的反馈不再可用时使用。 Martinel 等人在相似的性质中，建议为查询找到最相关的图库图像，将它们发送给人类标签，最后使用标签更新重新识别模型。自动重排方法也在几篇作品中进行了研究。Zheng 等人提出了一种查询自适应融合方法来组合多个 re-ID 系统的排序结果。具体而言，使用初始分数曲线的形状，并且认为该曲线对于良好特征呈现“L”形状。在[95]中，基于 CMC 曲线的直接优化来组合各种度量。 Garc'ıa 等人分析等级列表中的无监督鉴别上下文信息。这进一步与脱机中学到的重新排名度量结合在一起。 Leng 等人使用互惠邻近邻居的思想来改进基于离线步骤构建图像关系的初始秩列表。  \n",
    "\n",
    "重新排名仍然是个人重识别的开放方向，而它在实例检索中已经被广泛研究。应用场景可以描述如下。当搜索感兴趣的人时，由于图像变化频繁，很可能在某些相机下的图像很难找到。但是我们也许能够找到一些与 hard positives 更类似的结果。所以以这种方式，一旦简单的结果被返回，就可以找到hard positives。在实例检索中重新排序的方法可以很容易地通过人新识别。由于训练数据可用于 reID（表1），因此可以根据训练分布设计重排序方法。例如，当进行 k-NN 重排时，可根据得分从训练集中确定返回结果的有效性。由于重新识别的重点是行人，重排名方法可以专门设计。例如，在获得初始等级列表之后，可以选择排名靠前的图像的子集，并且可以检索包含它们的视频帧。随后，我们可以通过昂贵的滑动窗口方法找到最佳定位而不会产生太多的计算负担，从而避免检测器未对准的影响。  \n",
    "\n",
    "### 6.3 Open-World Person Re-ID  \n",
    "\n",
    "大多数现有的重识别作品可被视为识别任务。查询身份被假定存在于图库中，并且任务旨在确定查询的 ID。相比之下，开放世界的再认证系统研究个人验证问题。也就是说，基于识别任务，公开世界问题给方程增加了另一个条件。  \n",
    "\n",
    "$sim(q,g_{i^*}) > h$\n",
    "\n",
    "其中 h 是我们可以断言查询 q 属于身份 $i^*$ 的阈值;否则，q 被确定为不包含在图库中的离群值身份，尽管 $i^*$ 是识别过程中第一个排名的身份。  \n",
    "\n",
    "在文献中，开放世界的个人身份识别仍处于早期阶段，并提出了几项工作来帮助确定这一任务。Zheng 等人设计一个系统，由几个已知身份的观察列表和包括目标和非目标个体在内的多个探测器组成。他们的工作旨在实现 high true target recognition（TTR）和 low false target recognition（FTR）率，其计算被验证为查询总数的目标身份的查询数量的比率。Liao 等人将开放世界的再识别分成两个子任务，即检测和识别；前者决定图库中是否存在探针身份，后者是否向接受的探针分配了 ID。 因此提出了两种不同的评估指标，the detection and identification rate（DIR）和 the false accept rate（FAR），基于此可以绘制 ROC 曲线。  \n",
    "\n",
    "如[172]，[173]所示，开放世界的再识别仍然是一个具有挑战性的任务，如 low false accept rate下的低识别率问题。挑战主要在于两个方面，即检测和识别，这两个方面都局限于令人满意的匹配精度 - 这是标准重识别任务的研究重点。如[173]中所示，100% FAR 对应于标准关闭式 reID，其准确率受当前技术水平的限制；由于真实匹配的召回率低，因此较低的 FAR 伴随着较低的再识别准确性。因此，从技术角度来看，关键目标是提高匹配精度，在此基础上可以针对新颖性检测（验证）方法设计概率模型。而且，当关注重新识别的准确性时，开放世界的 reID 也应该考虑图库的动态。在一个具有不断传入的边界框的动态系统中，如果确定不属于任何现有的图库标识，则将新的标识添加到“观察列表”，反之亦然。动态注册新的身份可以自动建立数据库，并通过预先组织的图库方便重新识别过程。  \n",
    "\n",
    "## 7 CONCLUDING REMARKS  \n",
    "\n",
    "在本文中，对人员重识别进行了调查。首先介绍了人员身份识别的简要历史，介绍了其在图像分类和实例检索中的异同。然后，回顾现有的基于图像和基于视频的方法，这些方法分为手工制作和深度学习系统。定位在图像分类和实例检索之间，人员重识别距离成为一个准确和高效的应用程序还有很长的路要走。因此，从以前的调查中，本文更加强调了未完善但对未来重要的可能性上，例如集成了行人检测和跟踪的端到端身份识别系统，以及在非常大的图库中的个人身份识别，我们认为这是实际系统的必要步骤。我们还强调了一些可能引起社区进一步关注的重要公开问题。它们包括解决数据量问题，reID 重新排序方法和开放 reID 系统。总而言之，鉴别特征学习，检测器/跟踪优化和高效数据结构的整合将导致成功的人员重新识别系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepReID: Deep Filter Pairing Neural Network for Person Re-Identification  \n",
    "\n",
    "## Abstract  \n",
    "\n",
    "人员重新识别是为了匹配不相交摄像机视图中行人检测器检测到的行人图像。挑战以照明视角，姿势，视点，模糊效果，图像分辨率，相机设置，遮挡和背景混乱等各种复杂变化的形式呈现。另外，由行人检测器引起的不对准将影响大多数现有的人员重新识别方法，其使用手动裁剪的行人图像并假设完美的检测。  \n",
    "\n",
    "在本文中，我们提出了一种新的滤波器配对神经网络（FPNN）来联合处理不对齐，光度和几何变换，遮挡和背景杂波。所有关键部件都经过共同优化，以最大限度地提高每个部件与他人合作时的强度。与使用手工特征的现有作品相比，我们的方法自动从数据中学习最适合重新识别任务的特征。学习的滤波器对编码光度变换。它的深层架构可以模拟复杂的光度和几何变换。我们构建了 13164 幅 1360 个行人的最大基准数据集。与现有仅提供手动裁剪的行人图像数据集不同，我们的数据集提供了自动检测的边界框，用于接近实际应用的评估。我们的神经网络显着优于此数据集上的最新方法。  \n",
    "\n",
    "## 1. Introduction  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/1.jpg?raw=true)\n",
    "\n",
    "人员重新识别的目的是使在非重叠照相机视图中观察到的行人的视觉特征相匹配。它在视频监控中有着重要的应用，如跨摄像机跟踪，多摄像机事件检测和行人检索。这个问题非常具有挑战性，因为由于照明，姿势，视点，图像分辨率，摄像机的光度设置和混乱的背景的大的变化，在不同摄像机视图中难以匹配拍摄行人的视觉特征。图 1 显示了一些示例。  \n",
    "\n",
    "图 2 显示了人员重新识别系统的典型 pipline。实际上，它应该从自动行人检测开始，这是从长时间录制的视频中提取行人的重要步骤。给定行人检测边界框，现有作品中都使用手动设计的特征用于表征所有的图像区域，虽然它们可能不适合做人员重新识别的任务。由于照明条件和照相机设置的改变，同一个人的图像区域经历光度变换，它们的几何变换是由错位和视点和姿势的变化造成的。这种变换可以通过学习映射函数或相似性度量来标准化，它也被认为对于遮挡和背景混乱是强健的。所有现有的工程都可以分别或顺序优化管道中的每个模块。如果前面的步骤中丢失了有用的信息，则后面无法恢复。在训练过程中建立这些组件之间的自动交互对整个系统的性能至关重要。  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/2.jpg?raw=true)\n",
    "\n",
    "本文的贡献有三个。首先，我们提出了一种用于人员重新识别的滤波器配对神经网络（FPNN）。与现有作品相比，这种深度学习方法有几个重要的优点和新颖之处。（1）共同处理统一深度神经网络下的不对齐，光度和几何变换，遮挡和背景杂波。在训练期间，图 2 中的所有关键组件都进行了联合优化。每个组件在与他人合作时最大限度地发挥其优势。（2）除了使用手工制作的特征之外，它还可以自动学习数据重新识别任务的最佳特征，以及光度和几何变换的学习。两个配对滤镜应用于不同的相机视图以进行特征提取。（3）尽管现有作品假设交叉变换是 unimodal 的，但深层结构及其最大分组层可以模拟复杂变换的混合。  \n",
    "\n",
    "其次，我们用精心设计的训练策略训练提出的神经网络，包括损失，数据增强，数据平衡和 bootstrapping。这些策略解决了该任务中的误检，过拟合以及正面和负面训练样本极度不平衡的问题。  \n",
    "\n",
    "再次，我们重新审视人员再识别问题，建立一个引入自动行人检测之后可以进行评估的大规模数据集。所有现有的数据集都很小，这使得他们很难训练深度神经网络。我们的数据集有 1360 个行人的 13164 张图像；请参阅表 1 中的比较。现有数据集仅提供手动裁剪的行人图像，并假设评估协议中有完美的检测。如图 1 所示，实际中的自动检测会引起较大的错位，并可能严重影响现有方法的性能。我们的数据集提供了手动裁剪图像与使用最先进的检测器自动检测的边界框进行全面评估。  \n",
    "\n",
    "## 2. Related Work  \n",
    "\n",
    "许多研究旨在改善图 2 中管道的各个组成部分。现有人员重新识别系统中使用的视觉特征是手动设计的。全局特征用颜色和纹理的分布来描述视觉词的直方图。它们对于错位，姿态变化以及观点的变化有一些不变性。但是，由于失去了空间信息，他们的判别力很低。为了增加区分能力，已经使用了patch-based 局部特征。在计算两幅图像之间的相似度时，比较两个相应 patch 的视觉特征。解决错位问题时，挑战是在两个摄像机视图中匹配 patch。手工制作的特征很难实现辨别力和稳健性之间的平衡。最佳特征设计取决于摄像机视图中的光度和几何变换。例如，如果照度变化较大，则色彩空间应该以较粗糙的比例量化。如果特征设计与图 2 中的其他组件无关，则很难实现此类优化。虽然可以在后面的步骤中选择和加权特征，但如果特征池没有进行最佳设计，则性能会下降。正确的方法是与其他组件一起自动从数据中学习特征。如果没有深度学习，这很难实现。  \n",
    "\n",
    "人们可以假设光度或几何变换模型，并从训练样本中学习模型参数。例如，Prosser 等人假定光度变换是双向累积亮度传递函数，它将在一个摄像机视图中观察到的颜色映射到另一个。Porikli 通过相关矩阵分析了解了摄像机视图之间的颜色失真函数。他们假设变换是 unimodal 的。在我们提出的滤波器配对神经网络中，光度变换是通过滤波器对和 maxout grouping layer 来学习的。另一方面，几何变换是通过 patch matching 层，卷积最大化层和全连接层来学习的。提出的神经网络可以模拟复杂变换。  \n",
    "\n",
    "学习适当的距离/相似性度量可以进一步抑制交叉相机变换，遮挡和背景杂波的影响。Gray 等人和 Prosser 等分别使用 boosting 和 RankSVM 来选择特征并计算图像之间的距离。也有许多度量学习算法用于人员重新识别。图 2 中的所有组件都在现有作品中单独或顺序优化。  \n",
    "\n",
    "深度学习在解决许多计算机视觉问题方面取得了巨大的成功，包括手写数字识别，物体识别，物体检测，图像分类，场景理解和人脸识别。虽然一些深度学习作品分享共同优化视觉系统组件的精神，但他们的问题，挑战，模型和培训策略与我们完全不同。他们没有设计特殊的图层来明确处理多视图的光度和几何变换，patch matching 和背景混乱的错误检测。据我们所知，这篇论文是第一个使用深度学习进行人物识别的作品。  \n",
    "\n",
    "## 3. Model  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/3.jpg?raw=true)\n",
    "\n",
    "所提出的 FPNN 的架构如图 3 所示。它由六层组成，以处理未对准，多视图光度和几何变换，遮挡和背景混乱以及人员重新识别。下面介绍每层的设计。  \n",
    "\n",
    "### 3.1. Feature extraction  \n",
    "\n",
    "第一层是一个卷积和最大池化层。需要在不同摄像机视图中观察到两个行人图像 I 和 J 作为输入。他们有三个颜色通道（RGB 或 LAB），尺寸为Him×Wim。光度变换用卷积层建模，输出是由滤波器对提取的局部特征。通过对整个图像进行卷积滤波，将所有 local patches 的响应提取为局部特征。 应用于不同摄像机视图的滤镜（Wk，Vk）是成对的。如果使用 K1 个滤波器对并且每个滤波器的尺寸为 m1×m1×3，则每个图像的输出映射具有 K1 个通道并且大小为 H0×W0×K1，其中 $H_0 = H_{im}-m_1+1$ 和 $W_0 = W_{im}-m_1+1$，我们定义滤波函数 $f,g: R^{H_{im} \\times W_{im} \\times 3} \\rightarrow R^{H_{0} \\times W_{0} \\times K_1} $。 \n",
    "\n",
    "$f_{i,j}^k = \\sigma((W_k * I)_{i,j} + b_k^I)$  \n",
    "$g_{i,j}^k = \\sigma((V_k * J)_{i,j} + b_k^I)$\n",
    "\n",
    "卷积运算用 \\* 表示。使用非线性激活函数 $\\sigma(\\cdot)$ 来重新缩放线性输出并选择为 $\\sigma(x) = max(x,0)$。滤波后，每个补丁由一个 K1 通道特征向量表示。激活函数标准化和平衡不同的特征通道。自动从数据中学习滤波器对的参数 $\\{(W_k,V_k,b_k^I,b_k^J)\\}$。两个配对的滤波器代表了对人重新识别最具有区别性的相同特征。它们适用于不同的相机视图，它们的差异反映了光度变换。卷积层之后是 max-pooling，这使得这些特征对局部错位具有鲁棒性。每个特征映射被分割成 H1×W1 个子区域，每个子区域的最大响应作为输出。Max-pooling 层的输出是 H1×W1×K1 特征映射。  \n",
    "\n",
    "### 3.2. Patch matching  \n",
    "\n",
    "第二个 patch matching layer 用于匹配跨视图的 local patches 的滤波器响应。考虑到几何约束，行人图像被划分为 M 条水平条纹（图 3 中的高度因子），并且每条具有 W1 个贴片。图像 patches 仅在同一条纹内匹配。由于存在代表不同特征的 K1 滤波器对，所以 patch matching 层的输出为 $K_1MW_1 \\times W_1$ 的位移矩阵。patch matching 层的输出是  \n",
    "\n",
    "$S_{(i,j)(i',j')}^k = f_{ij}^kg_{i'j'}^k$\n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/4.jpg?raw=true)\n",
    "\n",
    "这些位移矩阵编码不同特征下 patch 匹配的空间模式。如图 4 所示。如果矩阵元素 $S_{(i,j)(i',j')}^k$ 具有较大值，则表明patches $(i,j)$ 和 $(i',j')$ 都具有对由滤波器对 $(W_k,V_k)$ 编码的特定特征的高响应。  \n",
    "\n",
    "### 3.3. Modeling mixture of photometric transforms  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/5.jpg?raw=true)\n",
    "\n",
    "由于各种视图内和视图间的变化，一个视觉特征（例如红色衣服）可能经历多次光度变换。为了提高 patch matching 的鲁棒性，增加了一个 maxout-grouping 层。K1 个特征通道的 patch 位移矩阵被分成 T 个组。在每个组中，只有最大激活被传递到下一层。这样，每个特征都由多个冗余通道表示。它允许建模混合的光度变换情况。在训练过程中，使用反向传播算法，只有具有最大响应的滤波器对才能接收梯度并进行更新。它驱动同一组中的过滤器对来竞争梯度。最终，只有一个过滤器对训练样本有很大的响应。因此，图像 patch 与学习的 filter 对具有稀疏的响应。众所周知，稀疏性有消除噪声和冗余的特性。maxout grouping 层的输出是 TMW1×W1 位移矩阵。如图 5 所示  \n",
    "\n",
    "### 3.4. Modeling part displacement  \n",
    "\n",
    "身体部位可以被视为相邻的 patches。在 patches 位移矩阵的顶部添加另一个 convolution and max-pooling layer，以更大尺度地获得身体部位的位移矩阵。它将 MTW1×W1 patches 位移矩阵作为输入，并将其作为具有 T 通道的 MW1×W1 图像。与第一个卷积层类似，对所有 M 个图像都应用 $K_2m_2×m_2×T$ 滤波器，该层的输出为 $MW_2×W_2×K_2$ 的特征图。学习的 filters 捕获部分位移的局部模式。  \n",
    "\n",
    "### 3.5. Modeling pose and viewpoint transforms  \n",
    "\n",
    "行人具有各种姿势和视点变换。这种全局几何变换可以看作局部位移的不同组合，它们的分布是多模式的。例如，两个转换可以在上半身共享相同的位移，但腿的位移不同。卷积和 maxpooling 层中的隐藏节点的每个输出可以被视为用特定的视觉特征检测到的可能的部分位移。所有这些隐藏节点构成下一个全连接层的输入向量。在下一层中，每个隐藏节点是所有可能的部分位移的组合，并且表示全局几何变换。N 个隐藏节点能够模拟全局的几何变换。  \n",
    "\n",
    "### 3.6. Identity Recognition  \n",
    "\n",
    "最后一个 softmax 图层使用 softmax 函数来测量两个输入图像是否属于同一个人，或者没有给出在前一图层中检测到的全局几何变换。它的输出是一个定义的二元变量 y。  \n",
    "\n",
    "如果两个行人图像 $(I_n,J_n)$ 匹配，令 y = 1，否则 y = 0。x 是来自前一层的输入, a0，a1，b0 和 b1 是要学习的组合权重和偏差项。给定 H 训练样本对的类别标签，负对数似然值用作训练 cost。\n",
    "\n",
    "$cost = - \\sum_n^H y_n \\log (p(y=1|\\Phi,(I_n,J_n))) + (1-y_n) \\log (1 - p(y=1|\\Phi,(I_n,J_n)))$\n",
    "\n",
    "它对错误分类的样品施加很大的惩罚。例如，如果 $y_n = 0$ 并且 $p (y=1|\\Phi,(I_n,J_n)) = 1$，$(1-y_n) \\log (1 - p(y=1|\\Phi,(I_n,J_n))) \\rightarrow - \\infinit$。 Φ表示要学习的整个神经网络的参数集合。  \n",
    "\n",
    "## 4. Training Strategies  \n",
    "\n",
    "我们的训练算法采用小批量随机梯度下降。训练数据划分为小批量。训练误差是在 soft-max 层中的每个小批量计算得到的，并且反推到较低层。此外，还提出了几种精心设计的训练策略。  \n",
    "\n",
    "### 4.1. Dropout  \n",
    "\n",
    "由于大量的交叉视图变化，错位，姿态变化和遮挡，个人重识别可能导致同一人（但在不同视图中）的某些 patches 不匹配。为了使训练好的 FPNN 可以容忍 patch 的错误检测，采用了 dropout 策略。对于每个训练样本作为每次训练迭代的输入，第一卷积层的一些输出被随机选择并设置为零，然后对经过 dropout 之后的特征图计算反向传播梯度，从而使模型更加鲁棒。  \n",
    "\n",
    "### 4.2. Data Augmentation  \n",
    "\n",
    "在训练集中，匹配的样本对（正样本）比不匹配的对（负样本）少几个数量级 如果他们直接用于训练，网络倾向于预测所有输入不匹配。我们通对每个行人图像进行简单的平移变换来增加数据。对于尺寸为 Him×Wim 的原始行人图像，在原始图像中心周围随机采样 5 幅相同大小的图像，匹配的样本对被放大25倍。  \n",
    "\n",
    "### 4.3. Data balancing  \n",
    "\n",
    "每个小批量保留所有正面训练样本，并在训练过程的最初阶段随机选择相同数量的负面训练样本。该网络在初始训练后达到了合理的良好配置。随着训练过程的进行，我们逐渐增加每个小批量中的负样品数量，使其达到 5：1 的比例。  \n",
    "\n",
    "### 4.4. Bootstrapping  \n",
    "\n",
    "在网络稳定后，我们继续选择 difficult negative samples，他们有很大概率被预测为同一个人，并将它们与所有正样本进行组合以迭代地进一步训练网络。由于存在大量的负面训练样本，在每个 epoch 后重新预测当前网络的所有负样本是非常耗时的。我们只重新预测在上一个 epoch 选择的困难样本。 由于这些样本已用于更新网络，因此预计其更新后的预测比其他样本的变化更大。  \n",
    "\n",
    "在每个 epoch k 之后，每个负样本 x 被赋予一个分数 sk。选择具有最小 sk 的样本重新训练网络。一开始，  \n",
    "\n",
    "$s_0 = 1 - p(x is a matched pair | \\Phi_0 )$\n",
    "\n",
    "其中 $\\Phi_0$ 是网络的配置。如果在前一个 epoch k 中选择 x 作为训练的困难样本，则其分数更新为  \n",
    "\n",
    "$s_k = \\frac{1 − p(x is a matched pair|\\Phi_k) + s_{k-1}}{2}$\n",
    "\n",
    "其中 $\\Phi_k$ 是在 epoch k 之后训练的网络的配置；$s_k = \\lambda s_{k-1}$。递减参数 $\\lambda$ 被设置为0.99。这增加了这些负样品很长时间不被选择的机会。  \n",
    "\n",
    "## 5. Dataset  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/6.jpg?raw=true)\n",
    "\n",
    "所有现有的数据集都太小而无法训练深度神经网络。我们构建了一个更大的数据集，其中包括 1360个行人的 13164 个图像。它被命名为 CUHK03，因为我们在以前的作品中已经发布了两个 re-id 数据集（CUHK01 和CUHK02）。表 1 中列出了这些数据集规模的比较。整个数据集由六台监视摄像机拍摄。每个身份由两个不相交的相机视图观察，并且在每个视图中平均具有 4.8 个图像。图 1（a）显示了一些示例。除了规模外，它还有以下特点  \n",
    "\n",
    "（1）除了手动裁剪的行人图像之外，我们还提供用最先进的行人检测器检测的样本。这是一个更现实的设置，并带来现有数据集中罕见的新问题。从图1（a）我们可以看出，这个数据集中失配，遮挡和身体部位缺失是相当普遍的。不准确的检测也使得几何变换变得复杂。我们进一步提供原始图像帧，研究人员可以在这个数据集上尝试自己的检测器。  \n",
    "\n",
    "（2）一些现有的数据集假设一对摄像机视图，并且它们的交叉视图变换相对简单。在我们的数据集中，从多对相机视图中收集的样本都是混合的，它们形成复杂的 crossview 变换。此外，我们的摄像头监控行人向不同方向行走的开放区域，从而导致即使在同一对摄像头之间进行多次视图变换。  \n",
    "\n",
    "（3）图像是从几个月内录制的一系列视频中获取的。即使在单个相机视图内，照明变化也是由天气，太阳方向和阴影分布引起的。我们的相机具有不同的设置，这也导致了光度变换。  \n",
    "\n",
    "## 6. Experimental Results  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/7.jpg?raw=true)\n",
    "\n",
    "大多数评估是在新数据集上进行的，因为现有数据集太小而无法训练深度模型，在CUHK01 也进行了评估。我们的数据集被分为训练集（1160人），验证集（100人）和测试集（100人）。每个人每个视图大约有 4.8 张照片，这意味着在数据增加之前，将有近 26000 个正样本训练对。mini-batch 包含 512 个图像对。因此，需要大约 300 个 mini-batch 才能过一遍训练集。验证集用于设计网络体系结构（参数如表 2 所示）。实验进行 20 次随机分割，所有累积匹配特征（CMC）曲线均为单次结果。  \n",
    "\n",
    "每个图像都使用直方图均衡进行预处理并转换为LAB色彩空间。它被标准化为（64×32×3）的大小，并且与该位置中的所有像素的平均值相减。我们的算法是用 GTX670 GPU 实现的。训练过程大约需要五个小时才能完成。  \n",
    "\n",
    "我们比较了三种重识别方法（KISSME，eSDC 和 SDALF），四种最先进的度量学习方法（信息理论度量学习（ITML）），Logistic 距离度量学习（LDM），最大边缘最近邻（LMNN）和 Metric Learning to Rank（RANK）），并直接使用欧几里得距离来比较特征。LMNN 和 ITML 是广泛使用的度量学习算法，并已被用于人员重识别。RANK 针对排序问题进行了优化，而人员重识别是排序问题。LDM 专门用于面部和人员识别问题。当使用度量学习方法和欧几里得距离，采用稠密颜色直方图和均匀采样补丁的密集 SIFT 的手工特征。通过广泛的实验评估，已经表明，这些局部特征比其他大多数特征对人员重识别更有效，并且公开可用。  \n",
    "\n",
    "### 6.1. Experiments on our new dataset  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/8.jpg?raw=true)\n",
    "\n",
    "在我们的 CUHK03 数据集上，我们使用手动标记的行人边界框和自动检测的边界框进行比较。图6（a）绘制使用手动标记边界框的 CMC 曲线。我们的 FPNN 优于所有方法。与最佳表现方法相比，Rank-1 识别率的相对改善程度为 46％。  \n",
    "\n",
    "图6（b）显示了使用自动检测的边界框的结果，这会导致未对齐。其他方法的性能显着下降。例如，表现最佳的 KISSME 的 Rank-1 识别率下降了 2.47％，而 FPNN 仅下降了 0.76％。它表明 FPNN 对未对准更加鲁棒。  \n",
    "\n",
    "为了比较不同学习方法的学习能力和泛化能力，我们做了另一项实验，在训练集中添加了 107 个行人的 933 个图像，同时保持测试集不变。因此，训练集有 1267人。这些额外的 933 个图像是从与测试集中不同的四个摄像机视图中捕获的。添加与测试集数据的光度和几何变换都不匹配的训练样本会使学习变得更加困难。图 6（c）显示了不同方法的 Rank-1 识别率的变化。据观察，大多数方法的性能下降，因为它们的有限学习能力不能有效地处理更复杂的训练集以及训练和测试集之间的不匹配。相反，由于 FPNN 的学习能力很大，并且额外的训练样本改善了可以由不同摄像机设置共享的学习低级特征，因此FPNN 的性能得到了提高。  \n",
    "\n",
    "### 6.2. Evaluation of training strategies  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/reID/2/9.jpg?raw=true)\n",
    "\n",
    "图7（a）和（b）中的实验显示了我们的 dropout and bootstrapping 训练策略的有效性。图7（a）显示验证集合上不同数量的 mini-batches 之后的 Rank-1 识别率，dropout rates 从 0％ 到 20％ 不等。没有 dropout rates，识别率会随着更多的 mini-batches 而降低。这表明过拟合发生。dropout rates 为 5％ 时，识别率很高，并收敛于验证集。dropout 使得训练好的 FPNN 可以容忍错误检测 patches ，并具有良好的泛化能力。如果 dropout rates 很高（例如20％2），即使泛化能力很好，它也不能达到很好的识别率，因为没有足够的特征传递到下一层。  \n",
    "\n",
    "图7（b）显示了有和没有 bootstrapping 策略的 FPNN 的 CMC 曲线。Bootstrapping 有效地将 Rank-1 识别率从 15.66％ 提高到 19.89％。然而，Rank-20 的差异较小。这可能是由于 Rank-20 后错过的样本特别困难，而 FPNN 已经放弃了适应这些极端情况以保持稳健。  \n",
    "\n",
    "### 6.3. Experiments on the CUHK01 dataset  \n",
    "\n",
    "我们在发布的 CUHK01 数据集上进一步评估 FPNN。在这个数据集中，有 971 个人，每个人在任一相机视图中只有两个图像。再次选择 100 人进行测试，其余 871 人进行训练和验证。这个数据集对我们的方法是具有挑战性的，因为少量的样本不能很好地训练深度模型。其上只有 3000 对正训练样本（与我们新数据集中的 26000 个样本相比）。尽管如此，我们的 FPNN 比较了大多数方法，Rank-1 比只略低于 KISSME，但是它的 Rank-n（n> 10）率与 KISSME 相当。  \n",
    "\n",
    "## 7. Conclusion  \n",
    "\n",
    "在本文中，我们提出了一种新的用于员重识别的滤波器配对神经网络。该方法在统一的深层架构下联合优化特征学习，光度变换，几何变换，未对齐，遮挡和分类。它学习滤波器对来编码光度变换。它的学习能力可以模拟复杂的光度和几何变换的混合。采用一些有效的训练训策略对网络进行良好的训练。它在大型基准数据集上的表现优于最先进的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考  \n",
    "\n",
    "- 1 [https://arxiv.org/abs/1610.02984](https://arxiv.org/abs/1610.02984)  \n",
    "- 2 [DeepReID: Deep Filter Pairing Neural Network for Person Re-Identification](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Li_DeepReID_Deep_Filter_2014_CVPR_paper.pdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
