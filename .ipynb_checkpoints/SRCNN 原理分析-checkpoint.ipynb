{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Super-Resolution Using Deep Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单幅图像超分辨率（SR），旨在从一个单一的低分辨率图像恢复高分辨率的图像，是计算机视觉中的经典问题。  \n",
    "该文章提出了一个全卷积神经网络的方法，直接学习低分辨率图像和高分辨率图像之间的端到端映射，几乎没有预处理/后处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摘要  \n",
    "\n",
    "1 对原始分辨率的图像进行下采样和上采样，构建对应的低分辨率图像，作为网络的训练数据，原始分辨率图像作为label  \n",
    "2 在原始图像上，有重叠的截取大小为33×33的的图像块，作为网络输入x，对应21×21大小的图像块作为label  \n",
    "3 以网络的输出和label 之间的均方误差作为网络的损失函数，优化网络参数  \n",
    "4 有人说用训练数据以14为步长，截取图像块，测试数据以21位步长截取图像块，可以缓解block artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 论文方法  \n",
    "\n",
    "### abstract  \n",
    "\n",
    "提出了一种单幅图像超分辨率的深度学习方法，直接学习低/高分辨率图像之间的端到端映射。该映射表示为深度卷积神经网络（CNN），其将低分辨率图像作为输入并输出高分辨率图像。  \n",
    "\n",
    "### introduction  \n",
    "\n",
    "单幅图像超分辨率（SR），旨在从一个单一的低分辨率图像恢复高分辨率的图像，是计算机视觉中的经典问题。 由于对于任何给定的低分辨率像素存在多种解决方案，这个问题本质上是不适定的。换句话说，这是一个欠定的反问题，其解决方案并不是唯一的。这样的问题通常通过强有力的先验信息约束解空间来进行缓解。  \n",
    "\n",
    "我们将所提出的模型称为超分辨率卷积神经网络（SRCNN）。提出的SRCNN有几个吸引人的属性。首先，其网络结构简单易行，但与现有的基于示例的方法相比，其精度更高，Figure 1 显示了比较的结果。其次，在中等数量的滤波器和层数下，我们的方法即使在CPU上也能实现快速的在线使用。我们的方法比许多基于示例的方法更快，因为它是完全前馈的，不需要解决任何使用上的优化问题。第三，实验表明，当有更大和更多不同的数据集可用时，或使用更大和更深的模型，可以进一步改善网络的恢复质量。相反，较大的数据集/模型可能会对现有的基于示例的方法提出挑战。此外，所提出的网络可以同时处理三路彩色图像，以实现改善的超分辨率性能。  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/SRCNN_1.jpg?raw=true)\n",
    "<center> ** Figure 1 ** </center >\n",
    "\n",
    "总的来说，这项研究的贡献主要有三个方面：  \n",
    "1）提出了一个完全卷积神经网络的方法。网络直接学习低分辨率图像和高分辨率图像之间的端到端映射，在优化之外几乎没有预处理/后处理。  \n",
    "2）建立了基于深度学习的SR方法和传统的基于稀疏编码的SR方法之间的关系。这种关系为网络结构的设计提供了指导。  \n",
    "3）证明深度学习在超分辨率的经典计算机视觉问题中是有用的，并且可以达到良好的质量和速度。  \n",
    "\n",
    "### related work  \n",
    "\n",
    "#### 图像超分辨率  \n",
    "\n",
    "根据图像先验知识，单幅图像超分辨率算法可以分为预测模型，基于边缘的方法，图像统计方法和基于块的（或基于实例的）方法四种类型。其中，基于实例的方法达到了最好的性能。  \n",
    "\n",
    "大多数 SR 算法专注于灰度或单通道图像超分辨率。对于彩色图像，上述方法首先将问题转换到不同的色彩空间（YCbCr 或 YUV），并且 SR 仅应用于亮度通道。 也有试图同时解决所有通道的方法。例如，Kim，Kwon 和 Dai et al。将它们的模型应用于每个 RGB 通道并将它们组合起来以产生最终结果。但是，他们中没有一个分析过不同通道的 SR 表现，以及这三个通道的恢复的必要性。  \n",
    "\n",
    "#### 卷积神经网络  \n",
    "\n",
    "卷积神经网络（CNN）可以追溯到几十年前，而深度 CNN 最近显示出爆炸性的受欢迎程度，部分原因是它在图像分类方面的成功。它们也被成功地应用于其他计算机视觉领域，例如目标检测，人脸识别和行人检测。在这个过程中，有几个因素是至关重要的：（1）现代强大的图形处理单元（GPU）的高效率训练实现;（2）整合线性单元（ReLU），这使得收敛速度更快，同时仍然具有良好的质量；以及（3）容易获得丰富的数据（如ImageNet）来训练较大的模型。 我们的方法也从这些进展中受益。  \n",
    "\n",
    "#### 深度学习图像恢复  \n",
    "\n",
    "已有一些使用深度学习技术进行图像恢复的研究。多层感知器（MLP）的所有层都是完全连接的（与卷积相反），被应用于自然图像去噪和去模糊后去噪。卷积神经网络与我们的工作更密切相关，被应用于自然图像去噪和去除噪声图案（污垢/雨）。这些恢复问题或多或少是由去噪驱动的。  \n",
    "\n",
    "### 用于超分辨率的卷积神经网络  \n",
    "\n",
    "![Aaron Swartz](https://github.com/liyibo/cv_notebooks/blob/master/markdown_pics/SRCNN_2.jpg?raw=true)\n",
    "<center> ** Figure 2 ** </center >\n",
    "\n",
    "#### 阐述  \n",
    "\n",
    "考虑一个单一的低分辨率图像，我们首先使用双三次插值将其采样到所需的大小，这是我们执行的唯一预处理。让我们将插值后的图像表示为 Y.我们的目标是从 Y 中恢复一个尽可能与真实高分辨率图像 X 相似的图像 F(Y)。为了便于表示，我们仍然称 Y 为“ 低分辨率“的图像，尽管它与 X 具有相同的尺寸。我们希望学习一个映射 F，它在概念上由三个操作组成：  \n",
    "\n",
    "1）图像块提取和表示：该操作从低分辨率图像 Y 中提取（重叠）图像块，并将每个图像块表示为高维向量。这些向量包括一组特征映射，其数目等于向量的维数。\n",
    "2）非线性映射：该操作将每个高维矢量非线性地映射到另一个高维矢量上。每个映射矢量在概念上是高分辨率图像块的表示。这些向量包含另一组特征映射。\n",
    "3）重建：该操作聚合上述高分辨率拼图表示以生成最终的高分辨率图像。预计该图像与 X 相似。  \n",
    "\n",
    "我们将这些操作形成一个卷积神经网络。 网络概述如 Figure 2 所示。接下来我们详细介绍每个操作的定义。  \n",
    "\n",
    "#### 图像块提取和表示  \n",
    "\n",
    "图像恢复中一个流行的策略是密集提取图像块块，然后用一组预先训练的方法，如 PCA，DCT，Haar 等来表示它们。这相当于将图像进行卷积，每个 filter 都是一种方法。在我们的表述中，我们将这些 filter 的优化纳入网络的优化。形式上，我们的第一层被表示为 F1 的操作：  \n",
    "\n",
    "F1(Y) = max (0, W1 ∗ Y + B1)  \n",
    "\n",
    "其中 W1和 B1 分别表示滤波器和偏差，\"∗\" 表示卷积运算。这里，W1 对应于支持 c×f1×f1 的 n1 个滤波器，其中 c 是输入图像中的通道数目，f1 是滤波器的空间尺寸。直观上，W1 对图像应用 n1 卷积，并且每个卷积具有核心大小 c×f1×f1。 输出由 n1 个特征映射组成。 B1 是一个 n1 维向量，其每个元素都与一个过滤器相关联。 \n",
    "\n",
    "#### 非线性映射  \n",
    "\n",
    "第一层提取每个图像块的 n1 维特征。在第二个操作中，我们将每个这些 n1 维向量映射到一个 n 维向量。  \n",
    "\n",
    "F2(Y) = max (0, W2 ∗ F1(Y) + B2)  \n",
    "\n",
    "输出 n 维矢量中的每一个在概念上都是将被用于重建的高分辨率图像块的表示。\n",
    "\n",
    "可以添加更多的卷积层来增加非线性。但是这会增加模型的复杂度，因此需要更多的训练时间。  \n",
    "\n",
    "#### 重建\n",
    "\n",
    "在传统方法中，预测的重叠高分辨率片通常被平均以产生最终的完整图像。平均值可以被认为是一组特征图上的预定义滤波器。受此启发，我们定义一个卷积层来产生最终的高分辨率图像：  \n",
    "\n",
    "F(Y) = W3 ∗ F2(Y) + B3  \n",
    "\n",
    "如果高分辨率图像块的表示在图像域，我们期望滤波器像平均滤波器那样工作;如果高分辨率片的表示在某些其他领域，我们期望 W3 的行为就像首先将系数投影到图像域上然后进行平均。无论如何，W3 是一组线性滤波器。\n",
    "\n",
    "有趣的是，虽然上述三种操作是由不同的直觉驱动的，但它们都形成了卷积层的形式。我们把这三个操作放在一起，形成一个卷积神经网络。在这个模型中，所有的滤波权重和偏差都将被优化。尽管总体结构简洁，但我们的 SRCNN 模型是通过吸取超分辨率方面的重大进展所带来的丰富经验而精心开发的。  \n",
    "\n",
    "### experiment  \n",
    "\n",
    "深度学习通常受益于大数据训练。为了进行比较，我们使用了由 91 幅图像组成的相对较小的训练集，以及 ILSVRC 2013 ImageNet 的 395909 幅图像组成的大型训练集。训练子图像的大小是 fsub = 33.因此，91 图像数据集可以被分解成 24,800 个子图像，这些子图像是从原始图像中以 14 的步幅提取的。而 ImageNet 提供了超过 500 万个子图像，我们使用基本的网络设置，即 f1 = 9，f2 = 1，f3 = 5，n1 = 64，n2 = 32。使用 Set5 作为验证集。  \n",
    "\n",
    "使用不同训练集的测试收敛曲线如 Figure 3 所示。由于反向传播的次数相同，因此 ImageNet上的训练时间与 91 图像数据集上的训练时间大致相同。可以观察到，在反向传播的数目相同（即8×108）的情况下，SRCNN + ImageNet 达到 32.52dB，高于在 91 幅图像上训练的 32.39dB。结果表明，使用更大的训练集可以进一步提高 SRCNN 的性能，但是大数据的效果并不像高级视觉问题那样明显。这主要是因为 91 幅图像已经捕捉到自然图像的充分变化。另一方面，我们的 SRCNN 是一个相对较小的网络（8,032个参数），不能适应91幅图像（24,800个样本）。 尽管如此，我们采用包含更多不同数据的 ImageNet 作为以下实验的默认训练集。  \n",
    "  \n",
    "### conclusion  \n",
    "\n",
    "我们提出了一种新颖的单一图像超分辨率（SR）的深度学习方法。 并表明，传统的基于稀疏编码的 SR 方法可以重构为深度卷积神经网络。所提出的方法SRCNN 学习了低分辨率和高分辨率图像之间的端到端映射，除了优化之外，还有少量额外的前/后处理。 SRCNN 结构轻巧，性能优于最先进的方法。我们猜想，通过探索更多的过滤器和不同的培训策略，可以进一步获得额外的表现。此外，所提出的结构具有简单性和鲁棒性的优点，可以应用于其他低级视觉问题，如图像去模糊或同步 SR 去噪。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 训练数据准备  \n",
    "\n",
    "1 根据91幅图像，以14位步长，截取大小为 33×33 的有重叠的图像块，共 24800 个输入图像，对应的 label 是 24800 个 21×21大小的高分辨率图像块    \n",
    "\n",
    "2 输入数据 x: 将原始图像下采样然后上采样 3 倍，这样构造低分辨率输入图像，然后有重叠的截取图像块，作为输入  \n",
    "\n",
    "3 输入数据对应的高分辨率图像label：在原始图像上，有重叠的截取大小为 21×21 的图像块，作为低分辨率图像对应的高分辨率图像，作为 label  \n",
    "\n",
    "4 网络结构卷积核的大小和个数分别为 9x9x64, 1x1x32 和 5x5x1的三层卷积网络  \n",
    "\n",
    "5 33×33 大小的图像经过 9x9, 1x1 和 5x5 的卷积之后，是 21×21 大小，可以与 label 对应起来计算loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(path, scale=3):\n",
    "  \"\"\"\n",
    "  输入图像作为label，经过采样之后的图像作为低分辨率输入图像\n",
    "  Preprocess single image file \n",
    "    (1) Read original image as YCbCr format (and grayscale as default)\n",
    "    (2) Normalize\n",
    "    (3) Apply image file with bicubic interpolation\n",
    "\n",
    "  Args:\n",
    "    path: file path of desired file\n",
    "    input_: image applied bicubic interpolation (low-resolution)\n",
    "    label_: image with original resolution (high-resolution)\n",
    "  \"\"\"\n",
    "  image = imread(path, is_grayscale=True)\n",
    "  label_ = modcrop(image, scale)\n",
    "\n",
    "  # Must be normalized\n",
    "  image = image / 255.\n",
    "  label_ = label_ / 255.\n",
    "\n",
    "  input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
    "  input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
    "\n",
    "  return input_, label_\n",
    "\n",
    "\"\"\"\n",
    "config.stride : 14\n",
    "config.image_size : 33\n",
    "config.label_size : 21\n",
    "padding : 12/2 = 6\n",
    "构建网络输入x 和 对应的标签 label\n",
    "\"\"\"\n",
    "for x in range(0, h-config.image_size+1, config.stride):\n",
    "    for y in range(0, w-config.image_size+1, config.stride):\n",
    "      sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n",
    "      sub_label = label_[x+padding:x+padding+config.label_size, y+padding:y+padding+config.label_size] # [21 x 21]\n",
    "\n",
    "      # Make channel value\n",
    "      sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n",
    "      sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n",
    "\n",
    "      sub_input_sequence.append(sub_input)\n",
    "      sub_label_sequence.append(sub_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 构建网络模型  \n",
    "\n",
    "1 网络结构十分简单，用了三个卷积层，三个卷积层使用的卷积核的大小和个数分别为 9x9x64, 1x1x32 和 5x5x1  \n",
    "\n",
    "2 网络的损失函数也比较简单，是网络输出与 label 之间的 mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(self):\n",
    "    self.images = tf.placeholder(tf.float32, [None, self.image_size, self.image_size, self.c_dim], name='images')\n",
    "    self.labels = tf.placeholder(tf.float32, [None, self.label_size, self.label_size, self.c_dim], name='labels')\n",
    "    \n",
    "    self.weights = {\n",
    "      'w1': tf.Variable(tf.random_normal([9, 9, 1, 64], stddev=1e-3), name='w1'),\n",
    "      'w2': tf.Variable(tf.random_normal([1, 1, 64, 32], stddev=1e-3), name='w2'),\n",
    "      'w3': tf.Variable(tf.random_normal([5, 5, 32, 1], stddev=1e-3), name='w3')\n",
    "    }\n",
    "    self.biases = {\n",
    "      'b1': tf.Variable(tf.zeros([64]), name='b1'),\n",
    "      'b2': tf.Variable(tf.zeros([32]), name='b2'),\n",
    "      'b3': tf.Variable(tf.zeros([1]), name='b3')\n",
    "    }\n",
    "\n",
    "    self.pred = self.model()\n",
    "\n",
    "    # Loss function (MSE)\n",
    "    self.loss = tf.reduce_mean(tf.square(self.labels - self.pred))\n",
    "    \n",
    "def model(self):\n",
    "    conv1 = tf.nn.relu(tf.nn.conv2d(self.images, self.weights['w1'], strides=[1,1,1,1], padding='VALID') + self.biases['b1'])\n",
    "    conv2 = tf.nn.relu(tf.nn.conv2d(conv1, self.weights['w2'], strides=[1,1,1,1], padding='VALID') + self.biases['b2'])\n",
    "    conv3 = tf.nn.conv2d(conv2, self.weights['w3'], strides=[1,1,1,1], padding='VALID') + self.biases['b3']\n",
    "    return conv3\n",
    "\n",
    "self.train_op = tf.train.GradientDescentOptimizer(config.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 测试数据准备与输出  \n",
    "\n",
    "1 根据测试图片截取大小为 33×33 的有重叠的图像块  \n",
    "2 送入网络，前向运算，输出结果  \n",
    "3 merge 输出的图像块，拼成测试图像对应的高分辨率图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构建测试数据图像块\n",
    "\"\"\"\n",
    "# Numbers of sub-images in height and width of image are needed to compute merge operation.\n",
    "nx = ny = 0 \n",
    "for x in range(0, h-config.image_size+1, config.stride):\n",
    "  nx += 1; ny = 0\n",
    "  for y in range(0, w-config.image_size+1, config.stride):\n",
    "    ny += 1\n",
    "    sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n",
    "    sub_label = label_[x+padding:x+padding+config.label_size, y+padding:y+padding+config.label_size] # [21 x 21]\n",
    "\n",
    "    sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n",
    "    sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n",
    "\n",
    "    sub_input_sequence.append(sub_input)\n",
    "    sub_label_sequence.append(sub_label)\n",
    "\n",
    "\"\"\"\n",
    "前向运行网络\n",
    "\"\"\"\n",
    "result = self.pred.eval({self.images: train_data, self.labels: train_label})\n",
    "\n",
    "\"\"\"\n",
    "输出结果merge，存图\n",
    "\"\"\"\n",
    "result = merge(result, [nx, ny])\n",
    "result = result.squeeze()\n",
    "image_path = os.path.join(os.getcwd(), config.sample_dir)\n",
    "image_path = os.path.join(image_path, \"test_image.png\")\n",
    "imsave(result, image_path)\n",
    "\n",
    "def merge(images, size):\n",
    "  h, w = images.shape[1], images.shape[2]\n",
    "  img = np.zeros((h*size[0], w*size[1], 1))\n",
    "  for idx, image in enumerate(images):\n",
    "    i = idx % size[1]\n",
    "    j = idx // size[1]\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考  \n",
    "\n",
    "1 [Image Super-Resolution Using Deep Convolutional Networks](https://arxiv.org/abs/1501.00092)  \n",
    "2 [SRCNN-Tensorflow](https://github.com/tegg89/SRCNN-Tensorflow)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
