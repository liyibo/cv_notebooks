{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Super-Resolution Using Deep Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们提出了一种单幅图像超分辨率的深度学习方法。我们的方法直接学习低/高分辨率图像之间的端到端映射。该映射表示为深度卷积神经网络（CNN），其将低分辨率图像作为输入并输出高分辨率图像。我们进一步表明，传统的基于稀疏编码的SR方法也可以被看作是一个深度卷积网络。但是不同于传统的分别处理每个组件的方法，我们的方法会联合优化所有层。我们的deep CNN结构轻巧，展现了最先进的修复质量，实现了实用的在线使用速度。我们探索不同的网络结构和参数设置，以实现性能和速度之间的折衷。而且，我们扩展了网络以同时处理三个颜色通道，并且显示更好的整体重建质量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单幅图像超分辨率（SR），旨在从一个单一的低分辨率图像恢复高分辨率的图像，是计算机视觉中的经典问题。 由于对于任何给定的低分辨率像素存在多种解决方案，这个问题本质上是不适定的。换句话说，这是一个欠定的反问题，其解决方案并不是唯一的。这样的问题通常通过强有力的先验信息约束解空间来进行缓解。为了学习先前的技术，最近的最先进的方法大多采用基于实例的策略。这些方法或者利用相同图像的内部相似性，或者从外部低分辨率和高分辨率示例学习映射函数。基于示例的外部方法可以用于通用图像超分辨率，或者可以根据提供的训练样本设计以适合特定领域的任务，即面部幻觉。  \n",
    "\n",
    "基于稀疏编码的方法是代表性的基于外部例子的SR方法之一。该方法涉及解决方案流程中的几个步骤。首先，从输入图像中紧密地裁剪重叠的块并进行预处理（例如，减去均值和归一化）。然后这些块由低分辨率字典编码。稀疏系数被传递到高分辨率字典中，用于重建高分辨率的块。将重叠的重新构建的贴片聚合（例如，通过加权平均）以产生最终输出。大多数外部的基于实例的方法共享这个流程，这些方法特别注意学习和优化字典或构建有效的映射函数。然而，流程中的其余步骤很少被优化或考虑在统一的优化框架中。  \n",
    "\n",
    "在本文中，我们表明上述流程相当于一个深层卷积神经网络（更多细节在3.2节）。受此事实的启发，我们考虑一个卷积神经网络，它直接学习低分辨率图像和高分辨率图像之间的端到端映射。我们的方法与现有的基于外部例子的方法有着根本的不同，因为我们没有明确地学习用于模拟块空间的字典，或流形。这隐含地通过隐藏层实现。此外，块提取和聚合也被制定为卷积层，因此涉及优化。在我们的方法中，整个SR流程是通过学习完全获得的，很少有前/后处理。  \n",
    "\n",
    "\n",
    "\n",
    "我们将所提出的模型称为超分辨率卷积神经网络（SRCNN）。拟议的SRCNN有几个吸引人的属性。首先，其结构是故意设计的，简单易行，但与现有的基于示例的方法相比，其精度更高。图1显示了一个例子的比较。其次，在中等数量的过滤器和层数下，我们的方法即使在CPU上也能实现快速的实际在线使用。我们的方法比许多基于示例的方法更快，因为它是完全前馈的，不需要解决任何使用上的优化问题。第三，实验表明，当（i）更大和更多不同的数据集可用时，和/或（ii）使用更大和更深的模型，可以进一步改善网络的恢复质量。相反，较大的数据集/模型可能会对现有的基于示例的方法提出挑战。此外，所提出的网络可以同时处理三路彩色图像，以实现改善的超分辨率性能。  \n",
    "\n",
    "总的来说，这项研究的贡献主要有三个方面：  \n",
    "1）我们图像超分辨率提出了一个完全卷积神经网络的方法。网络直接学习低分辨率图像和高分辨率图像之间的端到端映射，在优化之外几乎没有预处理/后处理。  \n",
    "2）我们建立了基于深度学习的SR方法和传统的基于稀疏编码的SR方法之间的关系。这种关系为网络结构的设计提供了指导。  \n",
    "3）我们证明深度学习在超分辨率的经典计算机视觉问题中是有用的，并且可以达到良好的质量和速度。  \n",
    "\n",
    "这项工作的初步版本早些时候提出。目前的工作在很大程度上增加了初始版本。首先，通过在非线性映射层中引入更大的滤波器大小来改进SRCNN，并通过添加非线性映射层来探索更深的结构。其次，我们扩展SRCNN来同时处理三个颜色通道（在YCbCr或RGB颜色空间中）。在实验上，我们证明，与单通道网络相比，性能可以提高。第三，新的分析和直观的解释被添加到最初的结果。我们还将原始实验从Set5 和Set14 测试图像扩展到BSD200（200个测试图像）。 另外，我们还比较了一些最近发表的方法，并确认我们的模型仍然优于现有的使用不同评估指标的方法。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "图像超分辨率  \n",
    "\n",
    "根据图像先验知识，单幅图像超分辨率算法可以分为预测模型，基于边缘的方法，图像统计方法和基于块的（或基于实例的）方法四种类型。 Yang等人的工作已经对这些方法进行了深入的研究和评估。其中，基于实例的方法达到了最好的性能。  \n",
    "\n",
    "内部的基于实例的方法利用了自相似性，并从输入图像中生成示例块。它首先在格拉斯纳的工作中提出，并提出了若干改进的变体来加速实施。基于外部示例的方法学习外部数据集的低/高分辨率块之间的映射。这些研究在如何学习一个紧凑的字典或流形空间来关联低分辨率的高分辨率的贴片以及如何在这样的空间中进行表示方案方面有所不同。在Freeman等人的先驱工作中。字典直接呈现为低分辨率高分辨率片对，并且在低分辨率空间中找到输入斑点的最近邻（NN），其相应的高分辨率斑点用于重建。 Chang等人引入了一种流形嵌入技术作为神经网络策略的替代方案。在杨等人的工作中，上述NN对应推进到更复杂的稀疏编码公式。为了进一步提高映射的准确性和速度，提出了其他映射函数，如核回归，简单函数，随机森林和锚定邻域回归。基于稀疏编码的方法及其几项改进是现今最先进的SR方法之一。在这些方法中，图像块是优化的重点;修补程序提取和聚合步骤被视为前/后处理和分开处理  \n",
    "\n",
    "大多数SR算法专注于灰度或单通道图像超分辨率。对于彩色图像，上述方法首先将问题转换到不同的色彩空间（YCbCr或YUV），并且SR仅应用于亮度通道。 也有试图同时解决所有渠道的作品。例如，Kim和Kwon和Dai et al。将它们的模型应用于每个RGB通道并将它们组合起来以产生最终结果。但是，他们中没有一个分析过不同渠道的SR表现，以及这三个渠道的恢复的必要性。  \n",
    "\n",
    "卷积神经网络  \n",
    "\n",
    "卷积神经网络（CNN）可以追溯到几十年前，而深度CNN最近显示出爆炸性的受欢迎程度，部分原因是它在图像分类方面的成功。它们也被成功地应用于其他计算机视觉领域，例如对象检测，人脸识别和行人检测。在这个过程中，有几个因素是至关重要的：（1）现代强大的图形处理单元（GPU）的高效率训练实现;（2）整合线性单元（ReLU），这使得收敛速度更快，同时仍然具有良好的质量；以及（3）容易获得丰富的数据（如ImageNet）来训练较大的模型。 我们的方法也从这些进展中受益。  \n",
    "\n",
    "深度学习图像恢复  \n",
    "\n",
    "已有一些使用深度学习技术进行图像恢复的研究。多层感知器（MLP）的所有层都是完全连接的（与卷积相反），被应用于自然图像去噪和去模糊后去噪。卷积神经网络与我们的工作更密切相关，被应用于自然图像去噪和去除噪声图案（污垢/雨）。这些恢复问题或多或少是由去噪驱动的。崔等提出采用基于内部实例的方法将自动编码器网络嵌入到他们的超分辨率流水线中。深层模型并不是专门设计为端到端的解决方案，因为级联的每一层都需要独立优化自相似性搜索过程和自动编码器。相反，所提出的SRCNN优化端到端映射。此外，SRCNN速度更快。这不仅是一个数量上更好的方法，而且也是一个实际有用的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于超分辨率的卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "阐述  \n",
    "\n",
    "考虑一个单一的低分辨率图像，我们首先使用双三次插值将其升级到所需的大小，这是我们执行的唯一预处理。让我们将插值后的图像表示为Y.我们的目标是从Y中恢复一个尽可能与真实高分辨率图像X相似的图像F(Y)。为了便于表示，我们仍然称Y为“ 低分辨率“的图像，尽管它与X具有相同的尺寸。我们希望学习一个映射F，它在概念上由三个操作组成：  \n",
    "\n",
    "1）图像块提取和表示：该操作从低分辨率图像Y中提取（重叠）图像块，并将每个图像块表示为高维向量。这些向量包括一组特征映射，其数目等于向量的维数。\n",
    "2）非线性映射：该操作将每个高维矢量非线性地映射到另一个高维矢量上。每个映射矢量在概念上是高分辨率图像块的表示。这些向量包含另一组特征映射。\n",
    "3）重建：该操作聚合上述高分辨率拼图表示以生成最终的高分辨率图像。预计该图像与X相似。  \n",
    "\n",
    "我们将展示所有这些操作形成一个卷积神经网络。 网络概述如图2所示。接下来我们详细介绍每个操作的定义。  \n",
    "\n",
    "图像块提取和表示  \n",
    "\n",
    "图像恢复中一个流行的策略（如[1]）是密集提取斑块，然后用一组预先训练的方法，如PCA，DCT，Haar等来表示它们。这相当于将图像进行卷积，每个filter都是一种方法。在我们的表述中，我们将这些filter的优化纳入网络的优化。形式上，我们的第一层被表示为F1的操作：  \n",
    "\n",
    "F1(Y) = max (0, W1 ∗ Y + B1)  \n",
    "\n",
    "其中W1和B1分别表示滤波器和偏差，\"∗\"表示卷积运算。这里，W1对应于支持c×f1×f1的n1个滤波器，其中c是输入图像中的通道数目，f1是滤波器的空间尺寸。 直观上，W1对图像应用n1卷积，并且每个卷积具有核心大小c×f1×f1。 输出由n1个特征映射组成。 B1是一个n1维向量，其每个元素都与一个过滤器相关联。 我们在滤波器响应4上应用整流线性单元（ReLU，max（0，x））  \n",
    "\n",
    "非线性映射  \n",
    "\n",
    "第一层提取每个图像块的n1维特征。在第二个操作中，我们将每个这些n1维向量映射到一个n维向量。这相当于应用平方空间支持1×1的n2滤波器。这个解释只对1×1滤波器有效。但是很容易推广到像3×3或5×5这样的较大的滤波器。在这种情况下，非线性映射不在输入图像的一个片上; 而是位于特征图的3×3或5×5“图像块”上。 第二层的操作是：  \n",
    "\n",
    "F2(Y) = max (0, W2 ∗ F1(Y) + B2)  \n",
    "\n",
    "这里W2包含尺寸为n1×f2×f2的n2个滤波器，并且B2是n2维的。输出n维矢量中的每一个在概念上都是将被用于重建的高分辨率图像块的表示。  \n",
    "\n",
    "可以添加更多的卷积层来增加非线性。但是这会增加模型的复杂度（一层的n2×f2×f2×n2参数），因此需要更多的训练时间。我们将在第4.3.3节中引入更多的非线性映射层来探索更深层次的结构。  \n",
    "\n",
    "重建\n",
    "\n",
    "在传统方法中，预测的重叠高分辨率片通常被平均以产生最终的完整图像。 平均值可以被认为是一组特征图上的预定义滤波器（其中每个位置是高分辨率片的“平坦”矢量形式）。 受此启发，我们定义一个卷积层来产生最终的高分辨率图像：  \n",
    "\n",
    "F(Y) = W3 ∗ F2(Y) + B3  \n",
    "\n",
    "这里W3对应于尺寸为n2×f3×f3的c个滤波器，并且B3是c维向量  \n",
    "\n",
    "如果高分辨率图像块的表示在图像域（即，我们可以简单地重塑每个表示形成片），我们期望滤波器像平均滤波器那样工作; 如果高分辨率片的表示在某些其他领域（例如，在一些基础上的系数），我们期望W3的行为就像首先将系数投影到图像域上然后进行平均。无论如何，W3是一组线性滤波器。\n",
    "\n",
    "有趣的是，虽然上述三种操作是由不同的直觉驱动的，但它们都形成了卷积层的形式。我们把这三个操作放在一起，形成一个卷积神经网络（图2）。在这个模型中，所有的滤波权重和偏差都将被优化。尽管总体结构简洁，但我们的SRCNN模型是通过吸取超分辨率方面的重大进展所带来的丰富经验而精心开发的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习端对端映射函数F需要估计网络参数Θ= {W1，W2，W3，B1，B2，B3}。 这是通过最小化重建图像F（Y;Θ）和相应的地面真实高分辨率图像X之间的损失来实现的。给定一组高分辨率图像{Xi}及其对应的低分辨率图像{Yi} 均方误差（MSE）作为损失函数：  \n",
    "\n",
    "公式  \n",
    "\n",
    "其中n是训练样本的数量。使用MSE作为损失函数有利于较高的PSNR。PSNR是定量评估图像恢复质量的一种广泛使用的指标，至少部分与感知质量有关。值得注意的是，如果只有损失函数是可导的，卷积神经网络不排除使用其他种类的损失函数。如果在训练期间给出更好的感知动机度量，则网络适应该度量是灵活的。相反，传统的“手工”方法通常难以实现这种灵活性。尽管所提出的模型被训练偏向于高PSNR，但是当使用替代评估度量（例如，SSIM，MSSIM）（参见第4.4.1节）评估模型时，我们仍然观察到令人满意的性能。  \n",
    "\n",
    "使用随机梯度下降和标准反向传播，损失最小化。 特别是，权重矩阵更新为  \n",
    "\n",
    "公式  \n",
    "\n",
    "其中∈{1,2,3}，i是层次和迭代的指标，η是学习率，∂L∂Wi是导数。每层的滤波器权重通过从具有零均值和标准偏差0.001的高斯分布中随机地进行初始化（并且针对偏差为0）。前两层的学习率是10-4，最后一层是10-5。我们经验地发现，最后一层较小的学习率对于网络收敛是重要的（类似于去噪情况）。  \n",
    "\n",
    "在训练阶段，将真实图像{Xi}准备为从训练图像中随机剪裁的fsub×fsub×c-pixel子图像。对于“子图像”，我们的意思是这些样本被视为小的“图像”，而不是“块”，在这种意义上，“块”是重叠的，并且需要一些平均值作为后处理，但“子图像”不需要。为了合成低分辨率样本{Yi}，我们用高斯核对子图像进行模糊处理，通过放大倍数对其进行子采样，并通过双三次插值以相同的因子对其进行放大。  \n",
    "\n",
    "为了避免训练期间的边界效应，所有的卷积层没有填充，网络产生较小的输出（（fsub-f1-f2-f3 + 3）2×c）。 MSE损失函数仅由Xi的中心像素与网络输出之间的差异来评估。 尽管我们在训练中使用了固定的图像大小，卷积神经网络可以在测试过程中应用于任意大小的图像。  \n",
    "\n",
    "我们使用cuda-convnet包实现我们的模型。 我们也尝试了Caffe软件[24]，并观察到类似的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先研究使用不同数据集对模型性能的影响。接下来，我们检查我们的方法学到的过滤器。然后，我们探索网络的不同架构设计，研究超分辨率性能与深度，滤波器数量和滤波器大小等因素之间的关系。随后，我们将我们的方法与近期的现有技术进行数量和质量上的比较。在[42]中，超分辨率仅应用于亮度通道（YCbCr色彩空间中的Y通道），因此在第一层/最后一层c = 1，性能（例如PSNR和SSIM）在Y频道评估。最后，我们扩展网络来处理彩色图像，并评估不同通道的表现。  \n",
    "\n",
    "训练数据  \n",
    "\n",
    "如文献所示，深度学习通常受益于大数据训练。为了进行比较，我们使用了由91幅图像组成的相对较小的训练集，以及ILSVRC 2013 ImageNet检测训练分区的395909幅图像组成的大型训练集。训练子图像的大小是fsub = 33.因此，91图像数据集可以被分解成24,800个子图像，这些子图像是从原始图像中以14的步幅提取的。而ImageNet提供了超过500万个子图像 我们使用基本的网络设置，即f1 = 9，f2 = 1，f3 = 5，n1 = 64，n2 = 32。我们使用Set5作为验证集。我们也观察到类似的趋势，即使我们使用更大的Set14集。放大倍数为3.我们使用基于稀疏编码的方法作为我们的基线，其平均PSNR值为31.42 dB。  \n",
    "\n",
    "使用不同训练集的测试收敛曲线如图4所示。由于反向传播的次数相同，因此ImageNet上的训练时间与91图像数据集上的训练时间大致相同。可以观察到，在反向传播的数目相同（即8×108）的情况下，SRCNN + ImageNet达到32.52dB，高于在91幅图像上训练的32.39dB。 结果正面表明，使用更大的训练集可以进一步提高SRCNN的性能，但是大数据的效果并不像高级视觉问题那样令人印象深刻。这主要是因为91幅图像已经捕捉到自然图像的充分变化。另一方面，我们的SRCNN是一个相对较小的网络（8,032个参数），不能适应91幅图像（24,800个样本）。 尽管如此，我们采用包含更多不同数据的ImageNet作为以下实验的默认训练集。  \n",
    "\n",
    "超分辨率学习到的filter  \n",
    "\n",
    "图5显示了通过放大倍数3在ImageNet上训练的已学习的第一层滤波器的示例。请参考我们已发布的放大倍数2和4的实现。有趣的是，每个学习滤波器都有其特定的功能。 例如，滤波器g和h就像拉普拉斯/高斯滤波器，滤波器a-e就像在不同方向上的边缘检测器，滤波器f就像一个纹理提取器。 图6中示出了不同层的示例特征图。显然，第一层的特征图包含不同结构（例如，不同方向上的边缘），而第二层的特征图在强度上主要是不同的。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经提出了一种新颖的单一图像超分辨率（SR）的深度学习方法。 我们表明，传统的基于稀疏编码的SR方法可以重构为深度卷积神经网络。所提出的方法SRCNN学习了低分辨率和高分辨率图像之间的端到端映射，除了优化之外，还有少量额外的前/后处理。 SRCNN结构轻巧，性能优于最先进的方法。我们猜想，通过探索更多的过滤器和不同的培训策略，可以进一步获得额外的表现。此外，所提出的结构具有简单性和鲁棒性的优点，可以应用于其他低级视觉问题，如图像去模糊或同步SR +去噪。 也可以调查一个网络来应对不同的升级因素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
