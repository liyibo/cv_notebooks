{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Review on Multi-Label Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract  \n",
    "\n",
    "多标签学习研究了每个样本同时与一组标签关联的问题。在过去的十年里，这个新兴的机器学习范式已经取得了相当大的进展。、本文旨在对这一领域进行及时的回顾，重点在于最先进的多标签学习算法。首先给出了多标签学习的基本原理，包括形式化定义和评估指标。其次，主要对 8 种具有代表性的多标签学习算法进行了相关分析和讨论。第三，简要总结了几个相关的学习设置。综上所述，本文概述了多标签学习的在线资源和开放性研究问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION  \n",
    "\n",
    "传统的监督学习是大多数学习的机器学习范例之一，其中每个现实世界的对象（例子）都是由一个实例（特征向量）来表示的，并且与单个标签相关联。 形式上，设 X表示实例空间，Y表示标签空间，传统监督学习的任务是从训练集{（xi，yi）|中学习函数f：X→Y。 1≤i≤m}。 这里，xi∈X是表征对象的属性（特征）的实例，yi∈Y是表征其语义的对应标签。 因此，传统监督学习所采用的一个基本假设是每个例子只属于一个概念，即具有独特的语义含义。    \n",
    "\n",
    "虽然传统的监督学习是盛行和成功的，但是由于现实世界中的对象可能是复杂的，同时具有多重的语义意义，所以上述简化的假设并不适合。 举几个例子，在文本分类中，新闻文件可以涵盖体育，伦敦奥运，售票和火炬接力等几个主题。 在音乐信息检索中，一首交响乐可以传达各种信息，如钢琴，古典音乐，莫扎特和奥地利; 在自动视频标注中，一个视频剪辑可能与一些场景相关，如城市和建筑等。  \n",
    "\n",
    "为了说明一个真实世界对象可能具有的多重语义含义，一个直接的解决方案就是给对象分配一组适当的标签来明确地表达它的语义。 经过上述考虑，多标签学习的范式自然会出现[95]。 与传统的监督式学习相反，在多标签学习中，每个对象也由单个实例来表示，而与一组标签相关联而不是单个标签。 这个任务是学习一个函数，它可以预测不可见实例的正确标签集合。  \n",
    "\n",
    "早期的多标签学习研究主要集中在多标签文本分类的问题[63，75，97]。 在过去的十年中，多标签学习已经逐渐引起了机器学习和相关社区的重视，并且已经被广泛地应用于包括图像在内的多媒体内容的自动标注在内的各种问题[5，67，74，85 生物信息学[16]，[27]，[107]，网络挖掘[51]，[82]，规则挖掘[84]，[99]，信息检索[35]，[114] 具体而言，近六年来（2007 - 2012年），主要机器学习相关会议上出现了60多篇带有关键词多标签（或多标签）的论文 包括ICML / ECML PKDD/IJCAI/AAAI/KDD/ICDM/NIPS \n",
    "\n",
    "本文对多标签学习的新兴领域进行了及时的回顾，其中最先进的分为三部分。第一部分（第二部分），多标签学习的基础知识包括正式的 定义（学习框架，关键挑战，阈值校准）和评估指标（基于实例，基于标签的理论结果）。 在第二部分和第一部分（第三部分）中，多达8个代表性多标签算法的技术细节在共同标记下进行审查，并进行必要的分析和讨论。 在第三部分（第四节），简要总结了几个相关的学习环境。 总结这个评论（第五部分），讨论了在线资源和未来的多标签学习研究的可能路线 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE PARADIGM  \n",
    "\n",
    "### A. Formal Definition  \n",
    "\n",
    "1）学习框架：假设X = Rd（或Zd）表示d维实例空间，Y = {y1，y2，...，yq}表示带有q个可能类标签的标签空间。 多标签学习的任务是从多标签训练集D = {（xi，Yi）|中学习函数h：X→2Y。 1≤i≤m}。 对于每个多标签的例子（xi，Yi），xi∈X是一个d维特征向量（xi1，xi2，... xid），Yi是与xi相关的标签集合。 看不见的实例x∈X，多标签分类器h（·）将h（x）predic Y预测为x的适当标签集合。  \n",
    "\n",
    "为了表征任何多标签数据集的属性，可以使用几个有用的多标签指示符[72]，[95]。 衡量多重标签度最自然的方法是标签基数：LCard（D）= m1 Pm i = 1 | Yi |，即每个例子的平均标签数量; 因此，标签密度通过标签空间中的可能标签的数量标签基数的标准化：LDen（D）= | Y | 1·LCard（D）。 另一种流行的多标签度量是标签多样性：LDiv（D）= | {Y | x x：（x，Y）∈D} |，即数据集中出现不同标号集的数量; 类似地，标签多样性可以通过示例的数量来标准化以指示不同标签组的比例：P LDiv（D）= | D | 1·LDiv（D）。  \n",
    "\n",
    "在大多数情况下，多标签学习系统返回的模型对应于一个实值函数f：X×Y→R，其中f（x，y）可以看作是y∈Y是x。 具体来说，给定一个多标签的例子（x，Y），f（·，·）应该在相关标签y'∈Y上产生较大的输出，而在不相关标签y“∈/ Y上输出较小的输出，即f ，y'）> f（x，y“）。 注意，多标签分类器h（·）可以通过以下公式得到实值函数f（·，·）：h（x）= {y | （x，y）> t（x），y∈Y}，其中t：X→R充当阈值函数，将标签空间二分为相关和不相关的标签集。  \n",
    "\n",
    "为便于参考，表I列出了本评论中使用的主要符号及其数学意义。  \n",
    "\n",
    "2）关键挑战：如果每个例子都被限制为只有一个标签，那么传统的监督学习就可以被看作是多标签学习的退化版本。 然而，多标签学习的普遍性不可避免地使相应的学习任务难以解决。 实际上，从多标签数据学习的关键挑战在于输出空间的压倒性大小，即随着类别标签数量的增加，标签集合的数量呈指数增长。 例如，对于具有20个类别标签（q = 20）的标签空间，可能的标签集合的数目将超过一百万（即220）  \n",
    "\n",
    "为了应对指数级输出空间的挑战，通过利用标签之间的相关性（或相关性）来促进学习过程是非常重要的[95]，[106]。 例如，如果我们知道标签“雨林”和“足球”，标签“巴西”标注的图片被标注的可能性就会很高; 如果文件涉及政治，文件不太可能被标记为娱乐。 因此，标签相关信息的有效利用被认为是多标签学习技术成功的关键。 根据学习技术已经考虑的相关性顺序，现有的标记相关性开发的策略可以大致分为三个家族[106]：  \n",
    "\n",
    "一阶策略：多标签学习的任务是逐个标签地处理，因此忽略了其他标签的共存，例如将多标签学习问题分解成许多独立的二元分类问题（每个标签一个）[5]，[16]，[108]。一阶策略的突出优点在于其概念简洁和高效率。另一方面，由于标签关联的无知，由此产生的方法的有效性可能不是最佳的。\n",
    "•二阶策略：通过考虑标签之间的成对关系来解决多标签学习的任务，例如相关标签与不相关标签之间的排序[27]，[30]，[107]标签[33]，[67]，[97]，[114]等。由于二阶策略在一定程度上利用了标签的相关性，所以得到了较好的泛化性能。然而，在某些真实世界的应用中，标签相关性超出了二阶假设。\n",
    "•高阶策略：通过考虑标签之间的高阶关系来解决多标签学习的任务，例如在每个标签上施加所有其他标签的影响[13]，[34]，[47]，[103]或处理标签的随机子集之间的连接[71]，[72]，[94]等。显然，高阶策略具有比一阶和二阶策略更强的相关建模能力，而另一方面是计算上的要求更高，可扩展性更差。  \n",
    "\n",
    "3）阈值校准：如第II-A1小节所述，多标签学习的一个常见做法是返回一些实值函数f（·，·）作为学习模型[95]。 在这种情况下，为了确定对于看不见的实例x（即h（x））的适当的标签集，每个标签上的实值输出f（x，y）应该相对于阈值函数输出t（x）。  \n",
    "\n",
    "通常，阈值校准可以用两种策略来完成，即将t（·）设置为常数函数或者从训练示例[44]中引入t（·）。 对于第一种策略，由于f（x，y）在R中取值，一个直接的选择是使用零作为校准常数[5]。 当f（x，y）表示y是x的适当标签的后验概率时，校准常数的另一个流行选择是0.5。 此外，当测试集中所有看不见的实例都可用时，可以设置校准常量以最小化训练集和测试集之间某些多标签指示符的差异，特别是标签基数[72]。  \n",
    "\n",
    "对于第二种策略，将使用堆叠式程序来确定阈值函数[27]，[69]，[107]。 一个流行的选择是假设一个t（·）的线性模型，即t（x）= hw *，f *（x）i + b *其中f *（x）=（f（x，y1） ·，f（x，yq））T∈Rq是一个q维堆叠向量，存储每个标签上的学习系统的实值输出。 具体来说，为了计算q维权向量w *和偏差b *，基于训练集D求解以下线性最小二乘问题：  \n",
    "\n",
    "公式\n",
    "\n",
    "这里s（xi）= argmina∈R| {yj | yj∈Yi，f（xi，yj）≤a} | + | {yk | yk∈Yi，f（xi，yk）≥a} |？ 表示堆叠模型的目标输出，其将Y分成相关和不相关的标签，用于每个训练实例具有最小错误分类。  \n",
    "\n",
    "上述所有的阈值校准策略都是通用技术，可以作为任何返回实值函数f（·，·）的多标签学习算法的后处理步骤。 因此，还存在一些特定的阈值校准技术，这些技术是特定于学习算法的[30]，[94]，并将在第三节作为其固有部分介绍。 代替使用阈值函数t（·），从f（·，·）诱导h（·）的等价机制是用t'来指定每个例子的相关标签的数量：X→{1,2，· ·，q}使得h（x）= {y | rankf（x，y）≤t'（x）} [44]，[82]。 在这里，当Y中的所有类标签按照f（x，·）降序排列时，rankf（x，y）返回y的等级。  \n",
    "\n",
    "### B. Evaluation Metrics  \n",
    "\n",
    "1）简单分类：在传统的监督学习中，学习系统的泛化性能通过传统的度量方法来评估，如精度，F-measure，ROC曲线下面积（AUC）等。然而，多标签学习中的性能评估是 比传统的单标签设置复杂得多，因为每个例子可以同时与多个标签相关联。 因此，提出了许多专门针对多标签学习的评估指标，通常可以将其分为两组，即基于实例的指标[33]，[34]，[75]和基于标签的指标[94]  \n",
    "\n",
    "按照表1中的符号，令S = {（xi，Yi）| 1≤i≤p）}为测试集，h（·）为学习的多标签分类器。 基于示例的度量标准通过分别在每个测试示例上评估学习系统的性能，然后返回整个测试集的平均值来工作。 与上述基于示例的度量标准不同，基于标签的度量标准是通过分别评估学习系统在每个类别标签上的性能，然后在所有类别标签上返回宏/微平均值  \n",
    "\n",
    "注意，关于h（·），学习系统的泛化性能是从分类角度来衡量的。 然而，无论是基于实例的还是基于标签的度量，关于大多数多标签学习系统作为惯例返回的实值函数f（？，？），泛化性能也可以从 排名视角。 图1总结了下面要介绍的主要多标签评估指标。  \n",
    "\n",
    "2）基于实例的度量：根据表1中的符号，可以基于多标签分类器h（·）[33]，[34]，[75]来定义6个基于实例的分类度量：  \n",
    "\n",
    "公式  \n",
    "\n",
    "子集精度评估正确分类的例子的分数，即预测的标签集合与地面实况标签集合相同。 直观地说，子集精度可以被认为是传统精度度量的多标签对应，并且往往过于严格，特别是当标签空间（即q）的大小很大时  \n",
    "\n",
    "公式  \n",
    "\n",
    "这里，Δ代表两组之间的对称差异。 汉明损失评估误分类的实例标签对的分数，即相关标签被遗漏或预测不相关。 请注意，当S中的每个例子仅与一个标签关联时，hlossS（h）将是传统错误分类率的2 / q倍。  \n",
    "\n",
    "公式 \n",
    "\n",
    "此外，Fexamβ是平衡因子β> 0的P recisionexam（h）和Recallexam（h）的综合版本。最常见的选择是β= 1，这导致了精确度和召回率的调和平均值。  \n",
    "\n",
    "当中间实值函数f（·，·）可用时，也可以定义四个基于实例的排序度量[75]：  \n",
    "\n",
    "公式  \n",
    "\n",
    "单错误评估排名靠前的标签不在相关标签集中的例子的比例  \n",
    "\n",
    "覆盖范围评估平均需要多少步骤才能向下移动排名标签列表，以覆盖示例的所有相关标签  \n",
    "\n",
    "排名损失评估反向排序标签对的比例，即不相关标签排名高于相关标签。  \n",
    "\n",
    "平均精度评估相关标签的平均分数高于特定标签y∈Yi。 对于一个错误，覆盖率和排名损失，度量值越小，系统的性能越好，最优值为1 pp i = 1 | Yi | -1，覆盖率为0，单错误和排名损失为0。 对于其他基于示例的多标签指标，度量值越大，系统性能越好，最优值为1  \n",
    "\n",
    "4）理论结果：基于度量的定义，很明显，现有的多标签度量从多个方面考虑性能，因此是不同的性质。 如第三节所示，大多数多标签学习算法实际上是通过显式或隐式地优化一个特定度量来从训练样例中学习的。 鉴于公平和诚实的评估，多标签学习算法的性能因此应该在广泛的度量标准上进行测试，而不是仅在被优化的那个标准上进行测试。 具体而言，最近的理论研究表明，分类器旨在最大化的子集精度将表现相当差，如果评估汉明损失，反之亦然[22]，[23]  \n",
    "\n",
    "由于多标签度量通常是非凸和不连续的，实际上大多数学习算法都采用优化（凸）替代多标签度量[65]，[66]。 最近，研究了多标签学习的一致性[32]，即随着训练集大小的增加，学习分类器的预期损失是否收敛于贝叶斯损失。 具体而言，给出了基于替代损失函数的多标签学习一致性的充分必要条件，这是直观的，可以非正式地表述为X×2Y上的一个固定分布，产生最优代理损失的分类器集合必须 落在产生最佳原始多标签损失的分类器集合中。  \n",
    "\n",
    "通过关注排名损失，发现标签对上定义的双向凸代理损失与排序损失一致，最近的多标签方法[40]即使对于确定性多标签学习也是不一致的[5]。有趣的是， ，与此相反，对于一致的多标签学习，报告了排名损失最小化的互补积极结果[21]。 通过使用双边排序问题的简化[55]，单个标签上定义的简单单变量凸代理损失（指数或逻辑）被证明与具有显式遗憾边界和收敛率的排名损失一致。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEARNING ALGORITHMS  \n",
    "\n",
    "### A. Simple Categorization  \n",
    "\n",
    "算法开发一直是机器学习研究的核心问题，多标签学习也不例外。 在过去的十年中，已经提出了大量的算法来从多标签数据中学习。 考虑到在有限的空间内通过所有现有的算法是不可行的，在这篇综述中我们选择了总共8个有代表性的多标签学习算法。 在这里，所选算法的代表性在以下标准中得到保持：a）广谱：每种算法具有独特的特征，覆盖各种算法设计策略; b）原始影响：大多数算法在其研究方向上产生了一些后续或相关的方法; 和c）有利的影响：每个算法都是多标签学习领域中引用率最高的作品之一  \n",
    "\n",
    "由于我们试图通过上述标准来减少选择的偏见，所以应该注意到八个算法的细节决不排除其他方法的重要性。 此外，为了符号一致性和数学严谨性，我们选择了在通用符号下改写和呈现每个算法。 在本文中，采用多标签学习算法的简单分类[95]：  \n",
    "\n",
    "问题转换方法：这类算法通过将多标签学习问题转化为其他完善的学习场景来解决问题。 代表性的算法包括二进制相关性[5]和高阶方法分类器链[72]，它将多标签学习任务转换为二进制分类任务，二阶方法校准标签排序[30] 多标签学习在标签排序任务中的应用，以及将多标签学习任务转化为多类分类任务的高阶方法Random k-labelsets [94]。  \n",
    "\n",
    "算法适应方法：这类算法通过适应流行的学习技术直接处理多标签数据来处理多标签学习问题。 具有代表性的算法包括一阶ML-kNN [108]适应惰性学习技术，一阶ML-DT [16]适应决策树技术，二阶方法Rank-SVM [27]适应核心技术， 顺序方法CML [33]适应信息论的技术。  \n",
    "\n",
    "简而言之，问题转换方法的关键原理是将数据拟合到算法中，而算法自适应方法的关键原则是将算法适用于数据。 图2总结了上面提到的算法，在本节的其余部分详细介绍  \n",
    "\n",
    "### B.问题转换方法  \n",
    "\n",
    "1）二元相关性：该算法的基本思想是将多标签学习问题分解为q个独立的二元分类问题，其中每个二元分类问题对应于标签空间中一个可能的标签[5]。  \n",
    "\n",
    "根据表1中的符号，对于第j类标签yj，二元相关性首先通过考虑每个训练样本与yj的相关性来构造相应的二元训练集：  \n",
    "\n",
    "公式  \n",
    "\n",
    "之后，利用一些二元学习算法B来导出二元分类器gj：X→R，即gj←B（Dj）。 因此，对于任何多标签训练样例（xi，Yi），实例xi将参与q个二元分类器的学习过程。 对于相关标签yj∈Yi，xi被认为是诱导gj（·）的一个正实例; 另一方面，对于不相关的标签yk∈Y¯i，xi被认为是一个负面的例子。 上述训练策略在[5]中被称为交叉训练，  \n",
    "\n",
    "对于看不见的实例x，二进制相关性通过查询每个单独二进制分类器上的标记相关性并且然后梳理相关标签来预测其相关联的标签集合Y：  \n",
    "\n",
    "公式  \n",
    "\n",
    "请注意，当所有二进制分类器产生负输出时，预测标签集合Y将是空的。 为了避免产生空的预测，可以应用以下T-标准规则：  \n",
    "\n",
    "简而言之，当没有一个二元分类器产生肯定的预测时，T-标准规则通过包括具有最大（负）最小输出的类别标签来补充式（4）。 除了T标准之外，还可以在文献[5]中找到基于每个二元分类器输出的其他标准集预测规则。  \n",
    "\n",
    "备注：二进制相关性的伪代码总结在图3中。它是一个一阶方法，它为每个标签分别构建分类器，为并行实现提供了天然的机会。 二元相关性的最突出的优点在于处理多标签数据的非常简单的方法（步骤1-4），其被用作许多最先进的多标签学习技术的构件[20 ]，[34]，[72]，[106]。 另一方面，二元相关性完全忽略了标签之间潜在的相关性，并且当q较大且标签密度（即LDen（D））较低时，每个标签的二元分类器可能遭遇类不平衡的问题。 如图3所示，二进制相关性具有用于训练的O（q·FB（m，d））和用于测试的O（q·FB'（d））的计算复杂度。  \n",
    "\n",
    "2）分类器链：这种算法的基本思想是将多标签学习问题转化为一个二元分类问题链，其中链中的后续二进制分类器是建立在前面的分类器的预测之上的[72]，[73]  \n",
    "\n",
    "对于q个可能的类标签{y1，y2，...，yq}，令τ：{1，...，q}→{1，...，q}是一个置换函数，用于指定一个排序 （1）≻yτ（2）··≻yτ（q）。 对于有序列表中的第j个标签yτ（j）（1≤j≤q），通过将每个实例附加到与yτ（j）之前的标签的相关性来构造相应的二进制训练集：  \n",
    "\n",
    "这里，[xi，preiτ（j）]连接向量xi和preiτ（j），preiτ（j）表示xi之前的那些标签的二进制赋值（具体地说，preiτ（1）= 然后，利用一些二元学习算法B来导出二元分类器gτ（j）：X×{-1，+ 1} j-1→R，即gτ（j）←B（Dτ））。 换句话说，gτ（j）（·）确定yτ（j）是否是相关的标签。  \n",
    "\n",
    "很明显，对于如上获得的分类器链，其有效性在很大程度上受τ指定的排序的影响。 为了说明排序的效果，可以在标签空间上用n个随机置换构建分类器链集合，即τ（1），τ（2），...，τ（n）。 对于每个置换τ（r）（1≤r≤n），通过将τ（r）直接应用于原始训练集合D，而不是通过引入一个分类器链，通过采样D使用修改的训练集合D（r） （| D（r）| = 0.67·| D |）[72]或置换（| D（r）| = | D |  \n",
    "\n",
    "备注：分类器链的伪代码总结在图4中。这是一个高阶方法，它以随机的方式考虑标签之间的相关性。 与二元相关性[5]相比，分类器链具有开发标签相关性的优点，但由于其链接属性而失去了并行实现的机会。 在训练阶段，分类器链通过地面实况标注（即等式（6）中的preiτ（j））增加具有额外特征的实例空间。 当由B返回的模型（例如朴素贝叶斯）能够产生后验概率时，另一种可能性是将它们设置为分类器的概率输出[20]，[105]。 如图4所示，分类器链的训练计算复杂度为O（q·FB（m，d + q）），测试的计算复杂度为O（q·FB'（d + q））  \n",
    "\n",
    "3）校准标签排名：该算法的基本思想是将多标签学习问题转化为标签排序问题，其中标签排名是通过两两比较的技术来实现的[30]  \n",
    "\n",
    "对于q个可能的类标签{y1，y2，...，yq}，可以通过成对比较产生总共q（q-1）/ 2个二值分类器，每个标签对（yj，yk） j <k≤q）。 具体而言，对于每个标签对（yj，yk），通过考虑每个训练样本与yj和yk的相对相关性，首先构造对应的二元训练集：  \n",
    "\n",
    "换句话说，只有与yj和yk有明显相关性的实例才会包含在Djk中。 之后，利用一些二进制学习算法B来导出二进制分类器gjk：X→R，即gjk←B（Djk）。 因此，对于任何多标签训练样本（xi，Yi），xi都将参与| Yi || Y ii |的学习过程。 二进制分类器。 对于任何实例x∈X，如果gjk（x）> 0，则学习系统投票给yj，否则投票给yk  \n",
    "\n",
    "对于看不见的实例x，校准标签排名首先将其馈送给q（q-1）/ 2训练的二元分类器，以获得每个可能的类标签上的整体投票：  \n",
    "\n",
    "基于上述定义，验证Pq j = 1ζ（x，yj）= q（q-1）/ 2并不困难。 在这里，Y中的标签可以根据各自的投票进行排序（任意断开关系）  \n",
    "\n",
    "此后，应该进一步指定一些阈值函数，将分级标签的列表分成相关和不相关的标签集合。 为了在成对比较框架内实现这一点，校准标签排名将虚拟标签yV合并到每个多标签训练示例（xi，Yi）中。 从概念上讲，虚拟标签是xi相关标签和不相关标签之间的人工分割点[6]。 换句话说，yV被认为排名低于yj∈Yi而排名高于yk∈Y¯i。  \n",
    "\n",
    "除了原始的q（q-1）/ 2二元分类器之外，将引入q个辅助二元分类器，每个新的标签对（yj，yV）（1≤j≤q）。 类似于（9），对应于（yj，yV）的二元训练集可以被构造如下：\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
